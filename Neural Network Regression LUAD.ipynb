{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zayeem00/MLProject_TeessideUni/blob/master/Neural%20Network%20Regression%20LUAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UgJo3g3hYkod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88022e3d-e94a-4159-b991-be91ccf21c8b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rjcx2KYzY3ug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZL50NhHNY3yn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "tar=pd.read_excel('survival_LUAD.xlsx')\n",
        "dt=pd.read_excel('LUAD.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OgFI5RBwY333",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "6a85f5ec-daba-4695-e7bb-f3e94cb85b80"
      },
      "cell_type": "code",
      "source": [
        "dt.head(2)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UBE2Q2P2</th>\n",
              "      <th>SSX9</th>\n",
              "      <th>CXORF67</th>\n",
              "      <th>EFCAB8</th>\n",
              "      <th>SDR16C6P</th>\n",
              "      <th>EFCAB12</th>\n",
              "      <th>A1BG</th>\n",
              "      <th>A1CF</th>\n",
              "      <th>RBFOX1</th>\n",
              "      <th>GGACT</th>\n",
              "      <th>...</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Patient's Vital Status</th>\n",
              "      <th>Disease Free (Months)</th>\n",
              "      <th>Person Cigarette Smoking History Pack Year Value</th>\n",
              "      <th>Fraction Genome Altered</th>\n",
              "      <th>Overall Survival Status</th>\n",
              "      <th>Disease Free Status</th>\n",
              "      <th>Person Neoplasm Status</th>\n",
              "      <th>Primary Tumor Site</th>\n",
              "      <th>Neoplasm Disease Stage American Joint Committee on Cancer Code3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HUG0_SYMBOL</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TCGA-05-4244-01</th>\n",
              "      <td>-0.4238</td>\n",
              "      <td>-0.1379</td>\n",
              "      <td>-0.1805</td>\n",
              "      <td>0.4529</td>\n",
              "      <td>-0.3317</td>\n",
              "      <td>-0.1012</td>\n",
              "      <td>-0.6977</td>\n",
              "      <td>-0.1476</td>\n",
              "      <td>-0.224</td>\n",
              "      <td>0.3832</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.456523</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-05-4249-01</th>\n",
              "      <td>-0.3291</td>\n",
              "      <td>-0.1379</td>\n",
              "      <td>-0.1805</td>\n",
              "      <td>-0.0869</td>\n",
              "      <td>-0.3317</td>\n",
              "      <td>-0.1661</td>\n",
              "      <td>-0.1483</td>\n",
              "      <td>-0.1371</td>\n",
              "      <td>-0.226</td>\n",
              "      <td>-0.5346</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>50.03</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.222128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 2864 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 UBE2Q2P2    SSX9  CXORF67  EFCAB8  SDR16C6P  EFCAB12    A1BG  \\\n",
              "HUG0_SYMBOL                                                                     \n",
              "TCGA-05-4244-01   -0.4238 -0.1379  -0.1805  0.4529   -0.3317  -0.1012 -0.6977   \n",
              "TCGA-05-4249-01   -0.3291 -0.1379  -0.1805 -0.0869   -0.3317  -0.1661 -0.1483   \n",
              "\n",
              "                   A1CF  RBFOX1   GGACT  \\\n",
              "HUG0_SYMBOL                               \n",
              "TCGA-05-4244-01 -0.1476  -0.224  0.3832   \n",
              "TCGA-05-4249-01 -0.1371  -0.226 -0.5346   \n",
              "\n",
              "                                              ...                                 \\\n",
              "HUG0_SYMBOL                                   ...                                  \n",
              "TCGA-05-4244-01                               ...                                  \n",
              "TCGA-05-4249-01                               ...                                  \n",
              "\n",
              "                 Sex  Patient's Vital Status  Disease Free (Months)  \\\n",
              "HUG0_SYMBOL                                                           \n",
              "TCGA-05-4244-01    0                       1                   0.00   \n",
              "TCGA-05-4249-01    0                       1                  50.03   \n",
              "\n",
              "                 Person Cigarette Smoking History Pack Year Value  \\\n",
              "HUG0_SYMBOL                                                         \n",
              "TCGA-05-4244-01                                              38.0   \n",
              "TCGA-05-4249-01                                              52.0   \n",
              "\n",
              "                 Fraction Genome Altered  Overall Survival Status  \\\n",
              "HUG0_SYMBOL                                                         \n",
              "TCGA-05-4244-01                 0.456523                        1   \n",
              "TCGA-05-4249-01                 0.222128                        1   \n",
              "\n",
              "                 Disease Free Status  Person Neoplasm Status  \\\n",
              "HUG0_SYMBOL                                                    \n",
              "TCGA-05-4244-01                    0                       0   \n",
              "TCGA-05-4249-01                    0                       0   \n",
              "\n",
              "                 Primary Tumor Site  \\\n",
              "HUG0_SYMBOL                           \n",
              "TCGA-05-4244-01                   5   \n",
              "TCGA-05-4249-01                   5   \n",
              "\n",
              "                 Neoplasm Disease Stage American Joint Committee on Cancer Code3  \n",
              "HUG0_SYMBOL                                                                       \n",
              "TCGA-05-4244-01                                                 10                \n",
              "TCGA-05-4249-01                                                  3                \n",
              "\n",
              "[2 rows x 2864 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "himGdNPE77yh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fed72513-b811-4244-b619-5b598ccc3dd5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(dt,tar,test_size=0.3)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(361, 2864) (361, 1)\n",
            "(156, 2864) (156, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pDAhhTJAY36_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "20e8aa1e-f50b-434f-8dc6-4a0248c5d424"
      },
      "cell_type": "code",
      "source": [
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_66 (Dense)             (None, 128)               366720    \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 531,585\n",
            "Trainable params: 531,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "foDpq4t2fWI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DE6LKTKgUqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dt=dt.set_index(dt.columns[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ay6Y0EuggAsA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6851
        },
        "outputId": "c59edb8a-5681-45d6-cdb4-69fae986e4aa"
      },
      "cell_type": "code",
      "source": [
        "NN_model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split = 0.2,callbacks=callbacks_list) \n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 288 samples, validate on 73 samples\n",
            "Epoch 1/100\n",
            "288/288 [==============================] - 0s 575us/step - loss: 1.0483 - mean_absolute_error: 1.0483 - val_loss: 15.8405 - val_mean_absolute_error: 15.8405\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 15.50315\n",
            "Epoch 2/100\n",
            "288/288 [==============================] - 0s 561us/step - loss: 1.1567 - mean_absolute_error: 1.1567 - val_loss: 16.2553 - val_mean_absolute_error: 16.2553\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 15.50315\n",
            "Epoch 3/100\n",
            "288/288 [==============================] - 0s 561us/step - loss: 1.2765 - mean_absolute_error: 1.2765 - val_loss: 15.9446 - val_mean_absolute_error: 15.9446\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 15.50315\n",
            "Epoch 4/100\n",
            "288/288 [==============================] - 0s 574us/step - loss: 1.2998 - mean_absolute_error: 1.2998 - val_loss: 16.0453 - val_mean_absolute_error: 16.0453\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 15.50315\n",
            "Epoch 5/100\n",
            "288/288 [==============================] - 0s 559us/step - loss: 1.5569 - mean_absolute_error: 1.5569 - val_loss: 15.8240 - val_mean_absolute_error: 15.8240\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 15.50315\n",
            "Epoch 6/100\n",
            "288/288 [==============================] - 0s 586us/step - loss: 1.2420 - mean_absolute_error: 1.2420 - val_loss: 15.8507 - val_mean_absolute_error: 15.8507\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 15.50315\n",
            "Epoch 7/100\n",
            "288/288 [==============================] - 0s 580us/step - loss: 1.3749 - mean_absolute_error: 1.3749 - val_loss: 16.0830 - val_mean_absolute_error: 16.0830\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 15.50315\n",
            "Epoch 8/100\n",
            "288/288 [==============================] - 0s 598us/step - loss: 1.4656 - mean_absolute_error: 1.4656 - val_loss: 15.6756 - val_mean_absolute_error: 15.6756\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 15.50315\n",
            "Epoch 9/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 1.1859 - mean_absolute_error: 1.1859 - val_loss: 15.8542 - val_mean_absolute_error: 15.8542\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 15.50315\n",
            "Epoch 10/100\n",
            "288/288 [==============================] - 0s 572us/step - loss: 1.7069 - mean_absolute_error: 1.7069 - val_loss: 15.8025 - val_mean_absolute_error: 15.8025\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 15.50315\n",
            "Epoch 11/100\n",
            "288/288 [==============================] - 0s 581us/step - loss: 1.5933 - mean_absolute_error: 1.5933 - val_loss: 15.8309 - val_mean_absolute_error: 15.8309\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 15.50315\n",
            "Epoch 12/100\n",
            "288/288 [==============================] - 0s 587us/step - loss: 1.4317 - mean_absolute_error: 1.4317 - val_loss: 15.6123 - val_mean_absolute_error: 15.6123\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 15.50315\n",
            "Epoch 13/100\n",
            "288/288 [==============================] - 0s 588us/step - loss: 1.0772 - mean_absolute_error: 1.0772 - val_loss: 15.8543 - val_mean_absolute_error: 15.8543\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 15.50315\n",
            "Epoch 14/100\n",
            "288/288 [==============================] - 0s 570us/step - loss: 1.1004 - mean_absolute_error: 1.1004 - val_loss: 15.9186 - val_mean_absolute_error: 15.9186\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 15.50315\n",
            "Epoch 15/100\n",
            "288/288 [==============================] - 0s 550us/step - loss: 1.0593 - mean_absolute_error: 1.0593 - val_loss: 15.6247 - val_mean_absolute_error: 15.6247\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 15.50315\n",
            "Epoch 16/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 0.9945 - mean_absolute_error: 0.9945 - val_loss: 16.0933 - val_mean_absolute_error: 16.0933\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 15.50315\n",
            "Epoch 17/100\n",
            "288/288 [==============================] - 0s 573us/step - loss: 1.0449 - mean_absolute_error: 1.0449 - val_loss: 15.3083 - val_mean_absolute_error: 15.3083\n",
            "\n",
            "Epoch 00017: val_loss improved from 15.50315 to 15.30834, saving model to Weights-017--15.30834.hdf5\n",
            "Epoch 18/100\n",
            "288/288 [==============================] - 0s 554us/step - loss: 0.9718 - mean_absolute_error: 0.9718 - val_loss: 15.7754 - val_mean_absolute_error: 15.7754\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 15.30834\n",
            "Epoch 19/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 0.9423 - mean_absolute_error: 0.9423 - val_loss: 16.0175 - val_mean_absolute_error: 16.0175\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 15.30834\n",
            "Epoch 20/100\n",
            "288/288 [==============================] - 0s 558us/step - loss: 1.0006 - mean_absolute_error: 1.0006 - val_loss: 15.5160 - val_mean_absolute_error: 15.5160\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 15.30834\n",
            "Epoch 21/100\n",
            "288/288 [==============================] - 0s 575us/step - loss: 0.9929 - mean_absolute_error: 0.9929 - val_loss: 15.2276 - val_mean_absolute_error: 15.2276\n",
            "\n",
            "Epoch 00021: val_loss improved from 15.30834 to 15.22762, saving model to Weights-021--15.22762.hdf5\n",
            "Epoch 22/100\n",
            "288/288 [==============================] - 0s 566us/step - loss: 1.0876 - mean_absolute_error: 1.0876 - val_loss: 15.3363 - val_mean_absolute_error: 15.3363\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 15.22762\n",
            "Epoch 23/100\n",
            "288/288 [==============================] - 0s 544us/step - loss: 1.0510 - mean_absolute_error: 1.0510 - val_loss: 15.3623 - val_mean_absolute_error: 15.3623\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 15.22762\n",
            "Epoch 24/100\n",
            "288/288 [==============================] - 0s 554us/step - loss: 1.2031 - mean_absolute_error: 1.2031 - val_loss: 15.4489 - val_mean_absolute_error: 15.4489\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 15.22762\n",
            "Epoch 25/100\n",
            "288/288 [==============================] - 0s 556us/step - loss: 1.1420 - mean_absolute_error: 1.1420 - val_loss: 15.2239 - val_mean_absolute_error: 15.2239\n",
            "\n",
            "Epoch 00025: val_loss improved from 15.22762 to 15.22393, saving model to Weights-025--15.22393.hdf5\n",
            "Epoch 26/100\n",
            "288/288 [==============================] - 0s 574us/step - loss: 1.1748 - mean_absolute_error: 1.1748 - val_loss: 15.6621 - val_mean_absolute_error: 15.6621\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 15.22393\n",
            "Epoch 27/100\n",
            "288/288 [==============================] - 0s 610us/step - loss: 0.9130 - mean_absolute_error: 0.9130 - val_loss: 15.6215 - val_mean_absolute_error: 15.6215\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 15.22393\n",
            "Epoch 28/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 1.1000 - mean_absolute_error: 1.1000 - val_loss: 15.4585 - val_mean_absolute_error: 15.4585\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 15.22393\n",
            "Epoch 29/100\n",
            "288/288 [==============================] - 0s 577us/step - loss: 1.0902 - mean_absolute_error: 1.0902 - val_loss: 15.5482 - val_mean_absolute_error: 15.5482\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 15.22393\n",
            "Epoch 30/100\n",
            "288/288 [==============================] - 0s 537us/step - loss: 0.9070 - mean_absolute_error: 0.9070 - val_loss: 15.6748 - val_mean_absolute_error: 15.6748\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 15.22393\n",
            "Epoch 31/100\n",
            "288/288 [==============================] - 0s 557us/step - loss: 1.0430 - mean_absolute_error: 1.0430 - val_loss: 15.5890 - val_mean_absolute_error: 15.5890\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 15.22393\n",
            "Epoch 32/100\n",
            "288/288 [==============================] - 0s 579us/step - loss: 0.9737 - mean_absolute_error: 0.9737 - val_loss: 15.3126 - val_mean_absolute_error: 15.3126\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 15.22393\n",
            "Epoch 33/100\n",
            "288/288 [==============================] - 0s 601us/step - loss: 0.9832 - mean_absolute_error: 0.9832 - val_loss: 15.7322 - val_mean_absolute_error: 15.7322\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 15.22393\n",
            "Epoch 34/100\n",
            "288/288 [==============================] - 0s 544us/step - loss: 1.2089 - mean_absolute_error: 1.2089 - val_loss: 15.6030 - val_mean_absolute_error: 15.6030\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 15.22393\n",
            "Epoch 35/100\n",
            "288/288 [==============================] - 0s 565us/step - loss: 1.2943 - mean_absolute_error: 1.2943 - val_loss: 15.2658 - val_mean_absolute_error: 15.2658\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 15.22393\n",
            "Epoch 36/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 1.3463 - mean_absolute_error: 1.3463 - val_loss: 15.6404 - val_mean_absolute_error: 15.6404\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 15.22393\n",
            "Epoch 37/100\n",
            "288/288 [==============================] - 0s 554us/step - loss: 1.0585 - mean_absolute_error: 1.0585 - val_loss: 15.1512 - val_mean_absolute_error: 15.1512\n",
            "\n",
            "Epoch 00037: val_loss improved from 15.22393 to 15.15118, saving model to Weights-037--15.15118.hdf5\n",
            "Epoch 38/100\n",
            "288/288 [==============================] - 0s 559us/step - loss: 1.0290 - mean_absolute_error: 1.0290 - val_loss: 15.6941 - val_mean_absolute_error: 15.6941\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 15.15118\n",
            "Epoch 39/100\n",
            "288/288 [==============================] - 0s 539us/step - loss: 1.0275 - mean_absolute_error: 1.0275 - val_loss: 15.7011 - val_mean_absolute_error: 15.7011\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 15.15118\n",
            "Epoch 40/100\n",
            "288/288 [==============================] - 0s 535us/step - loss: 0.9354 - mean_absolute_error: 0.9354 - val_loss: 15.5901 - val_mean_absolute_error: 15.5901\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 15.15118\n",
            "Epoch 41/100\n",
            "288/288 [==============================] - 0s 562us/step - loss: 1.0201 - mean_absolute_error: 1.0201 - val_loss: 15.3660 - val_mean_absolute_error: 15.3660\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 15.15118\n",
            "Epoch 42/100\n",
            "288/288 [==============================] - 0s 532us/step - loss: 0.8681 - mean_absolute_error: 0.8681 - val_loss: 15.4096 - val_mean_absolute_error: 15.4096\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 15.15118\n",
            "Epoch 43/100\n",
            "288/288 [==============================] - 0s 544us/step - loss: 1.0188 - mean_absolute_error: 1.0188 - val_loss: 15.5784 - val_mean_absolute_error: 15.5784\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 15.15118\n",
            "Epoch 44/100\n",
            "288/288 [==============================] - 0s 563us/step - loss: 1.0098 - mean_absolute_error: 1.0098 - val_loss: 15.8611 - val_mean_absolute_error: 15.8611\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 15.15118\n",
            "Epoch 45/100\n",
            "288/288 [==============================] - 0s 568us/step - loss: 1.0155 - mean_absolute_error: 1.0155 - val_loss: 15.7906 - val_mean_absolute_error: 15.7906\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 15.15118\n",
            "Epoch 46/100\n",
            "288/288 [==============================] - 0s 557us/step - loss: 1.1360 - mean_absolute_error: 1.1360 - val_loss: 15.5145 - val_mean_absolute_error: 15.5145\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 15.15118\n",
            "Epoch 47/100\n",
            "288/288 [==============================] - 0s 541us/step - loss: 1.2290 - mean_absolute_error: 1.2290 - val_loss: 15.6884 - val_mean_absolute_error: 15.6884\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 15.15118\n",
            "Epoch 48/100\n",
            "288/288 [==============================] - 0s 528us/step - loss: 1.5857 - mean_absolute_error: 1.5857 - val_loss: 15.6184 - val_mean_absolute_error: 15.6184\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 15.15118\n",
            "Epoch 49/100\n",
            "288/288 [==============================] - 0s 532us/step - loss: 1.3685 - mean_absolute_error: 1.3685 - val_loss: 15.4656 - val_mean_absolute_error: 15.4656\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 15.15118\n",
            "Epoch 50/100\n",
            "288/288 [==============================] - 0s 555us/step - loss: 1.1275 - mean_absolute_error: 1.1275 - val_loss: 15.5004 - val_mean_absolute_error: 15.5004\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 15.15118\n",
            "Epoch 51/100\n",
            "288/288 [==============================] - 0s 561us/step - loss: 0.9665 - mean_absolute_error: 0.9665 - val_loss: 15.5049 - val_mean_absolute_error: 15.5049\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 15.15118\n",
            "Epoch 52/100\n",
            "288/288 [==============================] - 0s 556us/step - loss: 0.9920 - mean_absolute_error: 0.9920 - val_loss: 15.6552 - val_mean_absolute_error: 15.6552\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 15.15118\n",
            "Epoch 53/100\n",
            "288/288 [==============================] - 0s 550us/step - loss: 0.8400 - mean_absolute_error: 0.8400 - val_loss: 15.5543 - val_mean_absolute_error: 15.5543\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 15.15118\n",
            "Epoch 54/100\n",
            "288/288 [==============================] - 0s 565us/step - loss: 0.9020 - mean_absolute_error: 0.9020 - val_loss: 15.6023 - val_mean_absolute_error: 15.6023\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 15.15118\n",
            "Epoch 55/100\n",
            "288/288 [==============================] - 0s 533us/step - loss: 0.9974 - mean_absolute_error: 0.9974 - val_loss: 15.7842 - val_mean_absolute_error: 15.7842\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 15.15118\n",
            "Epoch 56/100\n",
            "288/288 [==============================] - 0s 602us/step - loss: 0.8744 - mean_absolute_error: 0.8744 - val_loss: 15.7354 - val_mean_absolute_error: 15.7354\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 15.15118\n",
            "Epoch 57/100\n",
            "288/288 [==============================] - 0s 558us/step - loss: 1.0484 - mean_absolute_error: 1.0484 - val_loss: 15.6374 - val_mean_absolute_error: 15.6374\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 15.15118\n",
            "Epoch 58/100\n",
            "288/288 [==============================] - 0s 563us/step - loss: 1.0103 - mean_absolute_error: 1.0103 - val_loss: 15.3086 - val_mean_absolute_error: 15.3086\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 15.15118\n",
            "Epoch 59/100\n",
            "288/288 [==============================] - 0s 534us/step - loss: 0.9494 - mean_absolute_error: 0.9494 - val_loss: 15.3928 - val_mean_absolute_error: 15.3928\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 15.15118\n",
            "Epoch 60/100\n",
            "288/288 [==============================] - 0s 576us/step - loss: 0.9871 - mean_absolute_error: 0.9871 - val_loss: 15.6259 - val_mean_absolute_error: 15.6259\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 15.15118\n",
            "Epoch 61/100\n",
            "288/288 [==============================] - 0s 563us/step - loss: 1.0982 - mean_absolute_error: 1.0982 - val_loss: 15.4930 - val_mean_absolute_error: 15.4930\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 15.15118\n",
            "Epoch 62/100\n",
            "288/288 [==============================] - 0s 532us/step - loss: 0.9540 - mean_absolute_error: 0.9540 - val_loss: 15.8150 - val_mean_absolute_error: 15.8150\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 15.15118\n",
            "Epoch 63/100\n",
            "288/288 [==============================] - 0s 548us/step - loss: 0.9482 - mean_absolute_error: 0.9482 - val_loss: 15.4510 - val_mean_absolute_error: 15.4510\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 15.15118\n",
            "Epoch 64/100\n",
            "288/288 [==============================] - 0s 537us/step - loss: 1.2128 - mean_absolute_error: 1.2128 - val_loss: 15.8265 - val_mean_absolute_error: 15.8265\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 15.15118\n",
            "Epoch 65/100\n",
            "288/288 [==============================] - 0s 551us/step - loss: 1.3801 - mean_absolute_error: 1.3801 - val_loss: 15.9678 - val_mean_absolute_error: 15.9678\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 15.15118\n",
            "Epoch 66/100\n",
            "288/288 [==============================] - 0s 537us/step - loss: 1.1619 - mean_absolute_error: 1.1619 - val_loss: 15.5020 - val_mean_absolute_error: 15.5020\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 15.15118\n",
            "Epoch 67/100\n",
            "288/288 [==============================] - 0s 574us/step - loss: 1.0669 - mean_absolute_error: 1.0669 - val_loss: 15.6355 - val_mean_absolute_error: 15.6355\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 15.15118\n",
            "Epoch 68/100\n",
            "288/288 [==============================] - 0s 540us/step - loss: 1.0885 - mean_absolute_error: 1.0885 - val_loss: 15.6654 - val_mean_absolute_error: 15.6654\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 15.15118\n",
            "Epoch 69/100\n",
            "288/288 [==============================] - 0s 586us/step - loss: 0.8417 - mean_absolute_error: 0.8417 - val_loss: 15.4122 - val_mean_absolute_error: 15.4122\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 15.15118\n",
            "Epoch 70/100\n",
            "288/288 [==============================] - 0s 539us/step - loss: 1.0389 - mean_absolute_error: 1.0389 - val_loss: 15.6794 - val_mean_absolute_error: 15.6794\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 15.15118\n",
            "Epoch 71/100\n",
            "288/288 [==============================] - 0s 563us/step - loss: 1.0442 - mean_absolute_error: 1.0442 - val_loss: 15.4676 - val_mean_absolute_error: 15.4676\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 15.15118\n",
            "Epoch 72/100\n",
            "288/288 [==============================] - 0s 575us/step - loss: 1.2486 - mean_absolute_error: 1.2486 - val_loss: 15.4416 - val_mean_absolute_error: 15.4416\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 15.15118\n",
            "Epoch 73/100\n",
            "288/288 [==============================] - 0s 544us/step - loss: 1.0232 - mean_absolute_error: 1.0232 - val_loss: 15.2798 - val_mean_absolute_error: 15.2798\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 15.15118\n",
            "Epoch 74/100\n",
            "288/288 [==============================] - 0s 563us/step - loss: 0.9810 - mean_absolute_error: 0.9810 - val_loss: 15.5997 - val_mean_absolute_error: 15.5997\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 15.15118\n",
            "Epoch 75/100\n",
            "288/288 [==============================] - 0s 541us/step - loss: 1.2275 - mean_absolute_error: 1.2275 - val_loss: 15.4460 - val_mean_absolute_error: 15.4460\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 15.15118\n",
            "Epoch 76/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 1.0855 - mean_absolute_error: 1.0855 - val_loss: 15.5432 - val_mean_absolute_error: 15.5432\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 15.15118\n",
            "Epoch 77/100\n",
            "288/288 [==============================] - 0s 534us/step - loss: 1.0116 - mean_absolute_error: 1.0116 - val_loss: 15.3597 - val_mean_absolute_error: 15.3597\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 15.15118\n",
            "Epoch 78/100\n",
            "288/288 [==============================] - 0s 535us/step - loss: 0.9813 - mean_absolute_error: 0.9813 - val_loss: 15.4633 - val_mean_absolute_error: 15.4633\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 15.15118\n",
            "Epoch 79/100\n",
            "288/288 [==============================] - 0s 541us/step - loss: 1.0188 - mean_absolute_error: 1.0188 - val_loss: 15.8187 - val_mean_absolute_error: 15.8187\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 15.15118\n",
            "Epoch 80/100\n",
            "288/288 [==============================] - 0s 537us/step - loss: 0.9533 - mean_absolute_error: 0.9533 - val_loss: 15.6501 - val_mean_absolute_error: 15.6501\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 15.15118\n",
            "Epoch 81/100\n",
            "288/288 [==============================] - 0s 557us/step - loss: 1.0223 - mean_absolute_error: 1.0223 - val_loss: 15.3393 - val_mean_absolute_error: 15.3393\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 15.15118\n",
            "Epoch 82/100\n",
            "288/288 [==============================] - 0s 565us/step - loss: 1.0716 - mean_absolute_error: 1.0716 - val_loss: 15.0119 - val_mean_absolute_error: 15.0119\n",
            "\n",
            "Epoch 00082: val_loss improved from 15.15118 to 15.01186, saving model to Weights-082--15.01186.hdf5\n",
            "Epoch 83/100\n",
            "288/288 [==============================] - 0s 548us/step - loss: 0.9560 - mean_absolute_error: 0.9560 - val_loss: 15.7886 - val_mean_absolute_error: 15.7886\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 15.01186\n",
            "Epoch 84/100\n",
            "288/288 [==============================] - 0s 552us/step - loss: 0.9902 - mean_absolute_error: 0.9902 - val_loss: 15.2387 - val_mean_absolute_error: 15.2387\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 15.01186\n",
            "Epoch 85/100\n",
            "288/288 [==============================] - 0s 559us/step - loss: 0.9292 - mean_absolute_error: 0.9292 - val_loss: 15.4584 - val_mean_absolute_error: 15.4584\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 15.01186\n",
            "Epoch 86/100\n",
            "288/288 [==============================] - 0s 535us/step - loss: 1.0166 - mean_absolute_error: 1.0166 - val_loss: 15.3641 - val_mean_absolute_error: 15.3641\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 15.01186\n",
            "Epoch 87/100\n",
            "288/288 [==============================] - 0s 574us/step - loss: 1.0703 - mean_absolute_error: 1.0703 - val_loss: 15.6946 - val_mean_absolute_error: 15.6946\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 15.01186\n",
            "Epoch 88/100\n",
            "288/288 [==============================] - 0s 566us/step - loss: 1.0040 - mean_absolute_error: 1.0040 - val_loss: 15.5179 - val_mean_absolute_error: 15.5179\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 15.01186\n",
            "Epoch 89/100\n",
            "288/288 [==============================] - 0s 553us/step - loss: 0.9606 - mean_absolute_error: 0.9606 - val_loss: 15.8764 - val_mean_absolute_error: 15.8764\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 15.01186\n",
            "Epoch 90/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 0.9591 - mean_absolute_error: 0.9591 - val_loss: 15.4507 - val_mean_absolute_error: 15.4507\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 15.01186\n",
            "Epoch 91/100\n",
            "288/288 [==============================] - 0s 544us/step - loss: 0.9421 - mean_absolute_error: 0.9421 - val_loss: 15.5609 - val_mean_absolute_error: 15.5609\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 15.01186\n",
            "Epoch 92/100\n",
            "288/288 [==============================] - 0s 567us/step - loss: 1.0102 - mean_absolute_error: 1.0102 - val_loss: 15.5893 - val_mean_absolute_error: 15.5893\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 15.01186\n",
            "Epoch 93/100\n",
            "288/288 [==============================] - 0s 576us/step - loss: 1.3097 - mean_absolute_error: 1.3097 - val_loss: 15.5028 - val_mean_absolute_error: 15.5028\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 15.01186\n",
            "Epoch 94/100\n",
            "288/288 [==============================] - 0s 574us/step - loss: 1.2228 - mean_absolute_error: 1.2228 - val_loss: 15.4971 - val_mean_absolute_error: 15.4971\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 15.01186\n",
            "Epoch 95/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 1.1890 - mean_absolute_error: 1.1890 - val_loss: 15.6455 - val_mean_absolute_error: 15.6455\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 15.01186\n",
            "Epoch 96/100\n",
            "288/288 [==============================] - 0s 575us/step - loss: 0.9460 - mean_absolute_error: 0.9460 - val_loss: 15.5329 - val_mean_absolute_error: 15.5329\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 15.01186\n",
            "Epoch 97/100\n",
            "288/288 [==============================] - 0s 547us/step - loss: 0.8109 - mean_absolute_error: 0.8109 - val_loss: 15.4904 - val_mean_absolute_error: 15.4904\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 15.01186\n",
            "Epoch 98/100\n",
            "288/288 [==============================] - 0s 552us/step - loss: 1.0873 - mean_absolute_error: 1.0873 - val_loss: 15.2842 - val_mean_absolute_error: 15.2842\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 15.01186\n",
            "Epoch 99/100\n",
            "288/288 [==============================] - 0s 535us/step - loss: 0.8980 - mean_absolute_error: 0.8980 - val_loss: 15.5724 - val_mean_absolute_error: 15.5724\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 15.01186\n",
            "Epoch 100/100\n",
            "288/288 [==============================] - 0s 554us/step - loss: 0.9462 - mean_absolute_error: 0.9462 - val_loss: 15.4194 - val_mean_absolute_error: 15.4194\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 15.01186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82a7d38ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "metadata": {
        "id": "2T5s7sEDlIhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4df7d37b-505f-49fa-bc2d-ff7225397399"
      },
      "cell_type": "code",
      "source": [
        "predictions = NN_model.predict(X_train)\n",
        "type(predictions)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "metadata": {
        "id": "URQn2PFqgAy-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions=predictions.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8VNLYjb4ohzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "accuracy=r2_score(Y_train,predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nJq56_i8ov3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "67820bae-7195-486e-a551-a3028e777dd5"
      },
      "cell_type": "code",
      "source": [
        "print('train')\n",
        "print(accuracy)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "0.8852522673048104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6qxJkWUWzo6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6851
        },
        "outputId": "b44f1e60-917f-47df-f0e1-eec4897af3ab"
      },
      "cell_type": "code",
      "source": [
        "NN_model.fit(X_test, Y_test, epochs=100, batch_size=32, validation_split = 0.3,callbacks=callbacks_list) "
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109 samples, validate on 47 samples\n",
            "Epoch 1/100\n",
            "109/109 [==============================] - 0s 751us/step - loss: 14.5450 - mean_absolute_error: 14.5450 - val_loss: 12.9778 - val_mean_absolute_error: 12.9778\n",
            "\n",
            "Epoch 00001: val_loss improved from 15.01186 to 12.97783, saving model to Weights-001--12.97783.hdf5\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 584us/step - loss: 12.7144 - mean_absolute_error: 12.7144 - val_loss: 12.3036 - val_mean_absolute_error: 12.3036\n",
            "\n",
            "Epoch 00002: val_loss improved from 12.97783 to 12.30356, saving model to Weights-002--12.30356.hdf5\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 588us/step - loss: 10.4903 - mean_absolute_error: 10.4903 - val_loss: 11.7108 - val_mean_absolute_error: 11.7108\n",
            "\n",
            "Epoch 00003: val_loss improved from 12.30356 to 11.71082, saving model to Weights-003--11.71082.hdf5\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 581us/step - loss: 8.9189 - mean_absolute_error: 8.9189 - val_loss: 11.5599 - val_mean_absolute_error: 11.5599\n",
            "\n",
            "Epoch 00004: val_loss improved from 11.71082 to 11.55993, saving model to Weights-004--11.55993.hdf5\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 599us/step - loss: 6.4185 - mean_absolute_error: 6.4185 - val_loss: 11.4541 - val_mean_absolute_error: 11.4541\n",
            "\n",
            "Epoch 00005: val_loss improved from 11.55993 to 11.45406, saving model to Weights-005--11.45406.hdf5\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 697us/step - loss: 5.6473 - mean_absolute_error: 5.6473 - val_loss: 11.4798 - val_mean_absolute_error: 11.4798\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 11.45406\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 603us/step - loss: 4.9906 - mean_absolute_error: 4.9906 - val_loss: 11.2927 - val_mean_absolute_error: 11.2927\n",
            "\n",
            "Epoch 00007: val_loss improved from 11.45406 to 11.29267, saving model to Weights-007--11.29267.hdf5\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 564us/step - loss: 4.4241 - mean_absolute_error: 4.4241 - val_loss: 11.1243 - val_mean_absolute_error: 11.1243\n",
            "\n",
            "Epoch 00008: val_loss improved from 11.29267 to 11.12433, saving model to Weights-008--11.12433.hdf5\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 592us/step - loss: 3.5041 - mean_absolute_error: 3.5041 - val_loss: 11.0363 - val_mean_absolute_error: 11.0363\n",
            "\n",
            "Epoch 00009: val_loss improved from 11.12433 to 11.03631, saving model to Weights-009--11.03631.hdf5\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 623us/step - loss: 3.3128 - mean_absolute_error: 3.3128 - val_loss: 11.1536 - val_mean_absolute_error: 11.1536\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 11.03631\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 603us/step - loss: 2.7239 - mean_absolute_error: 2.7239 - val_loss: 11.3481 - val_mean_absolute_error: 11.3481\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 11.03631\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 592us/step - loss: 3.1042 - mean_absolute_error: 3.1042 - val_loss: 11.1233 - val_mean_absolute_error: 11.1233\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 11.03631\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 600us/step - loss: 2.6345 - mean_absolute_error: 2.6345 - val_loss: 11.2809 - val_mean_absolute_error: 11.2809\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 11.03631\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 581us/step - loss: 2.6233 - mean_absolute_error: 2.6233 - val_loss: 11.0077 - val_mean_absolute_error: 11.0077\n",
            "\n",
            "Epoch 00014: val_loss improved from 11.03631 to 11.00771, saving model to Weights-014--11.00771.hdf5\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 631us/step - loss: 2.5993 - mean_absolute_error: 2.5993 - val_loss: 11.1648 - val_mean_absolute_error: 11.1648\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 11.00771\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 645us/step - loss: 2.6306 - mean_absolute_error: 2.6306 - val_loss: 11.5840 - val_mean_absolute_error: 11.5840\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 11.00771\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 580us/step - loss: 2.5351 - mean_absolute_error: 2.5351 - val_loss: 11.2836 - val_mean_absolute_error: 11.2836\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 11.00771\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 642us/step - loss: 2.3138 - mean_absolute_error: 2.3138 - val_loss: 11.1534 - val_mean_absolute_error: 11.1534\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 11.00771\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 680us/step - loss: 2.1262 - mean_absolute_error: 2.1262 - val_loss: 11.3384 - val_mean_absolute_error: 11.3384\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 11.00771\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 611us/step - loss: 2.5761 - mean_absolute_error: 2.5761 - val_loss: 11.3234 - val_mean_absolute_error: 11.3234\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 11.00771\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 565us/step - loss: 2.6500 - mean_absolute_error: 2.6500 - val_loss: 11.5068 - val_mean_absolute_error: 11.5068\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 11.00771\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 661us/step - loss: 1.6758 - mean_absolute_error: 1.6758 - val_loss: 11.4100 - val_mean_absolute_error: 11.4100\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 11.00771\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 583us/step - loss: 2.0601 - mean_absolute_error: 2.0601 - val_loss: 11.3783 - val_mean_absolute_error: 11.3783\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 11.00771\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 618us/step - loss: 1.9775 - mean_absolute_error: 1.9775 - val_loss: 11.4585 - val_mean_absolute_error: 11.4585\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 11.00771\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 581us/step - loss: 1.9944 - mean_absolute_error: 1.9944 - val_loss: 11.4317 - val_mean_absolute_error: 11.4317\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 11.00771\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 582us/step - loss: 1.8837 - mean_absolute_error: 1.8837 - val_loss: 11.3379 - val_mean_absolute_error: 11.3379\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 11.00771\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 680us/step - loss: 2.2579 - mean_absolute_error: 2.2579 - val_loss: 11.7658 - val_mean_absolute_error: 11.7658\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 11.00771\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 595us/step - loss: 2.6877 - mean_absolute_error: 2.6877 - val_loss: 11.4114 - val_mean_absolute_error: 11.4114\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 11.00771\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 587us/step - loss: 3.0816 - mean_absolute_error: 3.0816 - val_loss: 11.5058 - val_mean_absolute_error: 11.5058\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 11.00771\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 538us/step - loss: 2.7346 - mean_absolute_error: 2.7346 - val_loss: 11.4660 - val_mean_absolute_error: 11.4660\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 11.00771\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 674us/step - loss: 1.9355 - mean_absolute_error: 1.9355 - val_loss: 11.2073 - val_mean_absolute_error: 11.2073\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 11.00771\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 616us/step - loss: 1.5729 - mean_absolute_error: 1.5729 - val_loss: 11.3308 - val_mean_absolute_error: 11.3308\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 11.00771\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 614us/step - loss: 1.2749 - mean_absolute_error: 1.2749 - val_loss: 11.1965 - val_mean_absolute_error: 11.1965\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 11.00771\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 625us/step - loss: 1.6407 - mean_absolute_error: 1.6407 - val_loss: 11.4021 - val_mean_absolute_error: 11.4021\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 11.00771\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 647us/step - loss: 1.7451 - mean_absolute_error: 1.7451 - val_loss: 11.1831 - val_mean_absolute_error: 11.1831\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 11.00771\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 657us/step - loss: 1.8124 - mean_absolute_error: 1.8124 - val_loss: 11.5237 - val_mean_absolute_error: 11.5237\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 11.00771\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 610us/step - loss: 2.1962 - mean_absolute_error: 2.1962 - val_loss: 11.2116 - val_mean_absolute_error: 11.2116\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 11.00771\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 685us/step - loss: 2.6626 - mean_absolute_error: 2.6626 - val_loss: 11.3034 - val_mean_absolute_error: 11.3034\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 11.00771\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 630us/step - loss: 2.3465 - mean_absolute_error: 2.3465 - val_loss: 11.3540 - val_mean_absolute_error: 11.3540\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 11.00771\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 670us/step - loss: 1.9589 - mean_absolute_error: 1.9589 - val_loss: 11.2361 - val_mean_absolute_error: 11.2361\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 11.00771\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 632us/step - loss: 1.4764 - mean_absolute_error: 1.4764 - val_loss: 11.5815 - val_mean_absolute_error: 11.5815\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 11.00771\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 661us/step - loss: 1.4097 - mean_absolute_error: 1.4097 - val_loss: 11.5755 - val_mean_absolute_error: 11.5755\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 11.00771\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 661us/step - loss: 1.5507 - mean_absolute_error: 1.5507 - val_loss: 11.5184 - val_mean_absolute_error: 11.5184\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 11.00771\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 606us/step - loss: 1.4140 - mean_absolute_error: 1.4140 - val_loss: 11.2762 - val_mean_absolute_error: 11.2762\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 11.00771\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 649us/step - loss: 1.3250 - mean_absolute_error: 1.3250 - val_loss: 11.4750 - val_mean_absolute_error: 11.4750\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 11.00771\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 679us/step - loss: 1.0776 - mean_absolute_error: 1.0776 - val_loss: 11.2652 - val_mean_absolute_error: 11.2652\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 11.00771\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 612us/step - loss: 1.4929 - mean_absolute_error: 1.4929 - val_loss: 11.4598 - val_mean_absolute_error: 11.4598\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 11.00771\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 625us/step - loss: 1.9011 - mean_absolute_error: 1.9011 - val_loss: 11.0559 - val_mean_absolute_error: 11.0559\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 11.00771\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 693us/step - loss: 2.1830 - mean_absolute_error: 2.1830 - val_loss: 11.4595 - val_mean_absolute_error: 11.4595\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 11.00771\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 618us/step - loss: 2.4771 - mean_absolute_error: 2.4771 - val_loss: 11.2914 - val_mean_absolute_error: 11.2914\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 11.00771\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 638us/step - loss: 2.4995 - mean_absolute_error: 2.4995 - val_loss: 11.6353 - val_mean_absolute_error: 11.6353\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 11.00771\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 624us/step - loss: 1.8496 - mean_absolute_error: 1.8496 - val_loss: 11.7475 - val_mean_absolute_error: 11.7475\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 11.00771\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 604us/step - loss: 1.5392 - mean_absolute_error: 1.5392 - val_loss: 11.5698 - val_mean_absolute_error: 11.5698\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 11.00771\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 684us/step - loss: 1.4391 - mean_absolute_error: 1.4391 - val_loss: 11.8132 - val_mean_absolute_error: 11.8132\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 11.00771\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 659us/step - loss: 1.1139 - mean_absolute_error: 1.1139 - val_loss: 11.4776 - val_mean_absolute_error: 11.4776\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 11.00771\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 591us/step - loss: 1.3689 - mean_absolute_error: 1.3689 - val_loss: 11.7260 - val_mean_absolute_error: 11.7260\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 11.00771\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 639us/step - loss: 1.8457 - mean_absolute_error: 1.8457 - val_loss: 11.3444 - val_mean_absolute_error: 11.3444\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 11.00771\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 654us/step - loss: 1.5048 - mean_absolute_error: 1.5048 - val_loss: 11.6101 - val_mean_absolute_error: 11.6101\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 11.00771\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 618us/step - loss: 1.5031 - mean_absolute_error: 1.5031 - val_loss: 11.5688 - val_mean_absolute_error: 11.5688\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 11.00771\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 648us/step - loss: 1.3127 - mean_absolute_error: 1.3127 - val_loss: 11.5666 - val_mean_absolute_error: 11.5666\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 11.00771\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 632us/step - loss: 1.2042 - mean_absolute_error: 1.2042 - val_loss: 11.4290 - val_mean_absolute_error: 11.4290\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 11.00771\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 596us/step - loss: 1.0436 - mean_absolute_error: 1.0436 - val_loss: 11.5783 - val_mean_absolute_error: 11.5783\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 11.00771\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 630us/step - loss: 1.0922 - mean_absolute_error: 1.0922 - val_loss: 11.5584 - val_mean_absolute_error: 11.5584\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 11.00771\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 649us/step - loss: 1.5461 - mean_absolute_error: 1.5461 - val_loss: 11.6948 - val_mean_absolute_error: 11.6948\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 11.00771\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 644us/step - loss: 1.5758 - mean_absolute_error: 1.5758 - val_loss: 11.6291 - val_mean_absolute_error: 11.6291\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 11.00771\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 652us/step - loss: 1.6023 - mean_absolute_error: 1.6023 - val_loss: 11.7627 - val_mean_absolute_error: 11.7627\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 11.00771\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 982us/step - loss: 1.5249 - mean_absolute_error: 1.5249 - val_loss: 11.4838 - val_mean_absolute_error: 11.4838\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 11.00771\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 723us/step - loss: 1.5228 - mean_absolute_error: 1.5228 - val_loss: 11.6658 - val_mean_absolute_error: 11.6658\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 11.00771\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 689us/step - loss: 1.0734 - mean_absolute_error: 1.0734 - val_loss: 11.5067 - val_mean_absolute_error: 11.5067\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 11.00771\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 645us/step - loss: 0.9835 - mean_absolute_error: 0.9835 - val_loss: 11.5298 - val_mean_absolute_error: 11.5298\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 11.00771\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 685us/step - loss: 1.1071 - mean_absolute_error: 1.1071 - val_loss: 11.5409 - val_mean_absolute_error: 11.5409\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 11.00771\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 666us/step - loss: 1.0732 - mean_absolute_error: 1.0732 - val_loss: 11.4022 - val_mean_absolute_error: 11.4022\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 11.00771\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 680us/step - loss: 1.2276 - mean_absolute_error: 1.2276 - val_loss: 11.6748 - val_mean_absolute_error: 11.6748\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 11.00771\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 606us/step - loss: 1.2652 - mean_absolute_error: 1.2652 - val_loss: 11.6671 - val_mean_absolute_error: 11.6671\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 11.00771\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 585us/step - loss: 1.1603 - mean_absolute_error: 1.1603 - val_loss: 11.4899 - val_mean_absolute_error: 11.4899\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 11.00771\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 603us/step - loss: 1.4150 - mean_absolute_error: 1.4150 - val_loss: 11.7481 - val_mean_absolute_error: 11.7481\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 11.00771\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 605us/step - loss: 1.3709 - mean_absolute_error: 1.3709 - val_loss: 11.5412 - val_mean_absolute_error: 11.5412\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 11.00771\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 702us/step - loss: 1.1929 - mean_absolute_error: 1.1929 - val_loss: 11.5617 - val_mean_absolute_error: 11.5617\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 11.00771\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 630us/step - loss: 1.1365 - mean_absolute_error: 1.1365 - val_loss: 11.4855 - val_mean_absolute_error: 11.4855\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 11.00771\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 621us/step - loss: 1.4356 - mean_absolute_error: 1.4356 - val_loss: 11.8524 - val_mean_absolute_error: 11.8524\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 11.00771\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 637us/step - loss: 1.2958 - mean_absolute_error: 1.2958 - val_loss: 11.4138 - val_mean_absolute_error: 11.4138\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 11.00771\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 626us/step - loss: 1.6948 - mean_absolute_error: 1.6948 - val_loss: 11.8291 - val_mean_absolute_error: 11.8291\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 11.00771\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 652us/step - loss: 2.2747 - mean_absolute_error: 2.2747 - val_loss: 11.3596 - val_mean_absolute_error: 11.3596\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 11.00771\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 661us/step - loss: 1.8798 - mean_absolute_error: 1.8798 - val_loss: 11.4772 - val_mean_absolute_error: 11.4772\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 11.00771\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 655us/step - loss: 1.7987 - mean_absolute_error: 1.7987 - val_loss: 11.6035 - val_mean_absolute_error: 11.6035\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 11.00771\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 670us/step - loss: 1.4804 - mean_absolute_error: 1.4804 - val_loss: 11.6827 - val_mean_absolute_error: 11.6827\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 11.00771\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 650us/step - loss: 1.6565 - mean_absolute_error: 1.6565 - val_loss: 11.7039 - val_mean_absolute_error: 11.7039\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 11.00771\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 750us/step - loss: 1.8941 - mean_absolute_error: 1.8941 - val_loss: 11.5956 - val_mean_absolute_error: 11.5956\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 11.00771\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 634us/step - loss: 1.2482 - mean_absolute_error: 1.2482 - val_loss: 11.6853 - val_mean_absolute_error: 11.6853\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 11.00771\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 667us/step - loss: 1.2673 - mean_absolute_error: 1.2673 - val_loss: 11.6292 - val_mean_absolute_error: 11.6292\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 11.00771\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 659us/step - loss: 1.1490 - mean_absolute_error: 1.1490 - val_loss: 11.6226 - val_mean_absolute_error: 11.6226\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 11.00771\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 645us/step - loss: 1.1090 - mean_absolute_error: 1.1090 - val_loss: 11.8155 - val_mean_absolute_error: 11.8155\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 11.00771\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 632us/step - loss: 1.0123 - mean_absolute_error: 1.0123 - val_loss: 11.6116 - val_mean_absolute_error: 11.6116\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 11.00771\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 640us/step - loss: 0.9066 - mean_absolute_error: 0.9066 - val_loss: 11.6619 - val_mean_absolute_error: 11.6619\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 11.00771\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 648us/step - loss: 0.9103 - mean_absolute_error: 0.9103 - val_loss: 11.5438 - val_mean_absolute_error: 11.5438\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 11.00771\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 635us/step - loss: 0.7988 - mean_absolute_error: 0.7988 - val_loss: 11.6629 - val_mean_absolute_error: 11.6629\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 11.00771\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 659us/step - loss: 1.1088 - mean_absolute_error: 1.1088 - val_loss: 11.7352 - val_mean_absolute_error: 11.7352\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 11.00771\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 642us/step - loss: 1.0002 - mean_absolute_error: 1.0002 - val_loss: 11.8348 - val_mean_absolute_error: 11.8348\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 11.00771\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 655us/step - loss: 0.8584 - mean_absolute_error: 0.8584 - val_loss: 11.8816 - val_mean_absolute_error: 11.8816\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 11.00771\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 699us/step - loss: 1.0593 - mean_absolute_error: 1.0593 - val_loss: 11.5342 - val_mean_absolute_error: 11.5342\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 11.00771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82a7d38e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "metadata": {
        "id": "zo42w0OU9bB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e0e6303-bf65-43fe-c7c1-b802a36cb186"
      },
      "cell_type": "code",
      "source": [
        "predictions = NN_model.predict(X_test)\n",
        "from sklearn.metrics import r2_score\n",
        "accuracy=r2_score(Y_test,predictions)\n",
        "print('test')\n",
        "print(accuracy)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test\n",
            "0.9001341767808023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ezr-69UyCLGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34187
        },
        "outputId": "0c9fd712-2b4c-41ab-b96b-e5fd44164ff8"
      },
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_regressor():\n",
        "    regressor = Sequential()\n",
        "    regressor.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
        "    regressor.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    regressor.add(Dense(units = 1, kernel_initializer = 'uniform'))\n",
        "    regressor.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "    return regressor\n",
        "regressorr = KerasRegressor(build_fn = build_regressor, batch_size = 10, epochs = 100)\n",
        "accuracies = cross_val_score(estimator = regressorr, X = X_train, y = Y_train, cv = 10, n_jobs = 1)\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "324/324 [==============================] - 3s 9ms/step - loss: 1737.2733 - mean_absolute_error: 29.6826\n",
            "Epoch 2/100\n",
            "324/324 [==============================] - 0s 360us/step - loss: 1653.5205 - mean_absolute_error: 28.4177\n",
            "Epoch 3/100\n",
            "324/324 [==============================] - 0s 328us/step - loss: 1225.6011 - mean_absolute_error: 22.0173\n",
            "Epoch 4/100\n",
            "324/324 [==============================] - 0s 333us/step - loss: 818.5316 - mean_absolute_error: 18.1947\n",
            "Epoch 5/100\n",
            "324/324 [==============================] - 0s 353us/step - loss: 637.2933 - mean_absolute_error: 16.4385\n",
            "Epoch 6/100\n",
            "324/324 [==============================] - 0s 369us/step - loss: 539.3444 - mean_absolute_error: 15.9601\n",
            "Epoch 7/100\n",
            "324/324 [==============================] - 0s 390us/step - loss: 449.8670 - mean_absolute_error: 14.6336\n",
            "Epoch 8/100\n",
            "324/324 [==============================] - 0s 365us/step - loss: 370.1855 - mean_absolute_error: 13.3362\n",
            "Epoch 9/100\n",
            "324/324 [==============================] - 0s 356us/step - loss: 295.3127 - mean_absolute_error: 12.0228\n",
            "Epoch 10/100\n",
            "324/324 [==============================] - 0s 376us/step - loss: 229.6858 - mean_absolute_error: 10.9281\n",
            "Epoch 11/100\n",
            "324/324 [==============================] - 0s 377us/step - loss: 176.4145 - mean_absolute_error: 9.4113\n",
            "Epoch 12/100\n",
            "324/324 [==============================] - 0s 354us/step - loss: 136.4273 - mean_absolute_error: 8.4286\n",
            "Epoch 13/100\n",
            "324/324 [==============================] - 0s 371us/step - loss: 107.1588 - mean_absolute_error: 7.2988\n",
            "Epoch 14/100\n",
            "324/324 [==============================] - 0s 368us/step - loss: 88.4428 - mean_absolute_error: 6.6184\n",
            "Epoch 15/100\n",
            "324/324 [==============================] - 0s 380us/step - loss: 72.1925 - mean_absolute_error: 5.7776\n",
            "Epoch 16/100\n",
            "324/324 [==============================] - 0s 385us/step - loss: 61.8700 - mean_absolute_error: 5.4207\n",
            "Epoch 17/100\n",
            "324/324 [==============================] - 0s 366us/step - loss: 53.4165 - mean_absolute_error: 4.9907\n",
            "Epoch 18/100\n",
            "324/324 [==============================] - 0s 368us/step - loss: 44.5948 - mean_absolute_error: 4.5089\n",
            "Epoch 19/100\n",
            "324/324 [==============================] - 0s 360us/step - loss: 38.5262 - mean_absolute_error: 4.1515\n",
            "Epoch 20/100\n",
            "324/324 [==============================] - 0s 320us/step - loss: 32.6884 - mean_absolute_error: 3.7803\n",
            "Epoch 21/100\n",
            "324/324 [==============================] - 0s 331us/step - loss: 28.1356 - mean_absolute_error: 3.5034\n",
            "Epoch 22/100\n",
            "324/324 [==============================] - 0s 335us/step - loss: 24.3204 - mean_absolute_error: 3.2659\n",
            "Epoch 23/100\n",
            "324/324 [==============================] - 0s 348us/step - loss: 21.3689 - mean_absolute_error: 3.0175\n",
            "Epoch 24/100\n",
            "324/324 [==============================] - 0s 355us/step - loss: 17.6542 - mean_absolute_error: 2.7668\n",
            "Epoch 25/100\n",
            "324/324 [==============================] - 0s 358us/step - loss: 15.3336 - mean_absolute_error: 2.5504\n",
            "Epoch 26/100\n",
            "324/324 [==============================] - 0s 332us/step - loss: 12.9196 - mean_absolute_error: 2.2830\n",
            "Epoch 27/100\n",
            "324/324 [==============================] - 0s 352us/step - loss: 11.3732 - mean_absolute_error: 2.1930\n",
            "Epoch 28/100\n",
            "324/324 [==============================] - 0s 366us/step - loss: 9.5576 - mean_absolute_error: 2.0375\n",
            "Epoch 29/100\n",
            "324/324 [==============================] - 0s 335us/step - loss: 8.2783 - mean_absolute_error: 1.8548\n",
            "Epoch 30/100\n",
            "324/324 [==============================] - 0s 355us/step - loss: 6.8411 - mean_absolute_error: 1.7212\n",
            "Epoch 31/100\n",
            "324/324 [==============================] - 0s 373us/step - loss: 5.9048 - mean_absolute_error: 1.5562\n",
            "Epoch 32/100\n",
            "324/324 [==============================] - 0s 403us/step - loss: 5.0296 - mean_absolute_error: 1.4578\n",
            "Epoch 33/100\n",
            "324/324 [==============================] - 0s 389us/step - loss: 4.2623 - mean_absolute_error: 1.2926\n",
            "Epoch 34/100\n",
            "324/324 [==============================] - 0s 329us/step - loss: 3.5733 - mean_absolute_error: 1.1917\n",
            "Epoch 35/100\n",
            "324/324 [==============================] - 0s 340us/step - loss: 2.8946 - mean_absolute_error: 1.0762\n",
            "Epoch 36/100\n",
            "324/324 [==============================] - 0s 340us/step - loss: 2.5381 - mean_absolute_error: 1.0028\n",
            "Epoch 37/100\n",
            "324/324 [==============================] - 0s 338us/step - loss: 2.1703 - mean_absolute_error: 0.9445\n",
            "Epoch 38/100\n",
            "324/324 [==============================] - 0s 359us/step - loss: 1.8378 - mean_absolute_error: 0.8429\n",
            "Epoch 39/100\n",
            "324/324 [==============================] - 0s 369us/step - loss: 2.1589 - mean_absolute_error: 0.8296\n",
            "Epoch 40/100\n",
            "324/324 [==============================] - 0s 338us/step - loss: 1.3488 - mean_absolute_error: 0.7137\n",
            "Epoch 41/100\n",
            "324/324 [==============================] - 0s 349us/step - loss: 1.1569 - mean_absolute_error: 0.6465\n",
            "Epoch 42/100\n",
            "324/324 [==============================] - 0s 331us/step - loss: 0.9588 - mean_absolute_error: 0.5960\n",
            "Epoch 43/100\n",
            "324/324 [==============================] - 0s 330us/step - loss: 0.7953 - mean_absolute_error: 0.5332\n",
            "Epoch 44/100\n",
            "324/324 [==============================] - 0s 330us/step - loss: 0.6449 - mean_absolute_error: 0.4615\n",
            "Epoch 45/100\n",
            "324/324 [==============================] - 0s 330us/step - loss: 0.5582 - mean_absolute_error: 0.4344\n",
            "Epoch 46/100\n",
            "324/324 [==============================] - 0s 328us/step - loss: 0.4776 - mean_absolute_error: 0.3845\n",
            "Epoch 47/100\n",
            "324/324 [==============================] - 0s 331us/step - loss: 0.4618 - mean_absolute_error: 0.3729\n",
            "Epoch 48/100\n",
            "324/324 [==============================] - 0s 329us/step - loss: 0.4153 - mean_absolute_error: 0.3790\n",
            "Epoch 49/100\n",
            "324/324 [==============================] - 0s 383us/step - loss: 0.3476 - mean_absolute_error: 0.3184\n",
            "Epoch 50/100\n",
            "324/324 [==============================] - 0s 370us/step - loss: 0.3264 - mean_absolute_error: 0.2910\n",
            "Epoch 51/100\n",
            "324/324 [==============================] - 0s 375us/step - loss: 0.3053 - mean_absolute_error: 0.2769\n",
            "Epoch 52/100\n",
            "324/324 [==============================] - 0s 360us/step - loss: 0.2480 - mean_absolute_error: 0.2460\n",
            "Epoch 53/100\n",
            "324/324 [==============================] - 0s 365us/step - loss: 0.2326 - mean_absolute_error: 0.2259\n",
            "Epoch 54/100\n",
            "324/324 [==============================] - 0s 361us/step - loss: 0.2302 - mean_absolute_error: 0.2235\n",
            "Epoch 55/100\n",
            "324/324 [==============================] - 0s 339us/step - loss: 0.2108 - mean_absolute_error: 0.2080\n",
            "Epoch 56/100\n",
            "324/324 [==============================] - 0s 402us/step - loss: 0.1937 - mean_absolute_error: 0.2063\n",
            "Epoch 57/100\n",
            "324/324 [==============================] - 0s 353us/step - loss: 0.1882 - mean_absolute_error: 0.2077\n",
            "Epoch 58/100\n",
            "324/324 [==============================] - 0s 361us/step - loss: 0.2127 - mean_absolute_error: 0.2062\n",
            "Epoch 59/100\n",
            "324/324 [==============================] - 0s 381us/step - loss: 0.2084 - mean_absolute_error: 0.2069\n",
            "Epoch 60/100\n",
            "324/324 [==============================] - 0s 328us/step - loss: 0.1773 - mean_absolute_error: 0.1858\n",
            "Epoch 61/100\n",
            "324/324 [==============================] - 0s 325us/step - loss: 0.1865 - mean_absolute_error: 0.1885\n",
            "Epoch 62/100\n",
            "324/324 [==============================] - 0s 362us/step - loss: 0.2089 - mean_absolute_error: 0.2308\n",
            "Epoch 63/100\n",
            "324/324 [==============================] - 0s 371us/step - loss: 0.2236 - mean_absolute_error: 0.2223\n",
            "Epoch 64/100\n",
            "324/324 [==============================] - 0s 372us/step - loss: 0.2730 - mean_absolute_error: 0.2282\n",
            "Epoch 65/100\n",
            "324/324 [==============================] - 0s 332us/step - loss: 0.3421 - mean_absolute_error: 0.2551\n",
            "Epoch 66/100\n",
            "324/324 [==============================] - 0s 374us/step - loss: 0.4153 - mean_absolute_error: 0.2872\n",
            "Epoch 67/100\n",
            "324/324 [==============================] - 0s 330us/step - loss: 0.4136 - mean_absolute_error: 0.2744\n",
            "Epoch 68/100\n",
            "324/324 [==============================] - 0s 370us/step - loss: 0.4788 - mean_absolute_error: 0.2999\n",
            "Epoch 69/100\n",
            "324/324 [==============================] - 0s 389us/step - loss: 0.3620 - mean_absolute_error: 0.3152\n",
            "Epoch 70/100\n",
            "324/324 [==============================] - 0s 384us/step - loss: 0.2897 - mean_absolute_error: 0.3046\n",
            "Epoch 71/100\n",
            "324/324 [==============================] - 0s 332us/step - loss: 0.3390 - mean_absolute_error: 0.3099\n",
            "Epoch 72/100\n",
            "324/324 [==============================] - 0s 340us/step - loss: 0.2700 - mean_absolute_error: 0.2969\n",
            "Epoch 73/100\n",
            "324/324 [==============================] - 0s 361us/step - loss: 0.2246 - mean_absolute_error: 0.2510\n",
            "Epoch 74/100\n",
            "324/324 [==============================] - 0s 361us/step - loss: 0.2332 - mean_absolute_error: 0.2590\n",
            "Epoch 75/100\n",
            "324/324 [==============================] - 0s 363us/step - loss: 0.2658 - mean_absolute_error: 0.2726\n",
            "Epoch 76/100\n",
            "324/324 [==============================] - 0s 363us/step - loss: 0.2668 - mean_absolute_error: 0.2727\n",
            "Epoch 77/100\n",
            "324/324 [==============================] - 0s 373us/step - loss: 0.2848 - mean_absolute_error: 0.2906\n",
            "Epoch 78/100\n",
            "324/324 [==============================] - 0s 352us/step - loss: 0.3712 - mean_absolute_error: 0.3491\n",
            "Epoch 79/100\n",
            "324/324 [==============================] - 0s 326us/step - loss: 0.4732 - mean_absolute_error: 0.3815\n",
            "Epoch 80/100\n",
            "324/324 [==============================] - 0s 370us/step - loss: 0.5514 - mean_absolute_error: 0.4204\n",
            "Epoch 81/100\n",
            "324/324 [==============================] - 0s 366us/step - loss: 0.7557 - mean_absolute_error: 0.4791\n",
            "Epoch 82/100\n",
            "324/324 [==============================] - 0s 377us/step - loss: 0.8463 - mean_absolute_error: 0.5705\n",
            "Epoch 83/100\n",
            "324/324 [==============================] - 0s 370us/step - loss: 0.9464 - mean_absolute_error: 0.5736\n",
            "Epoch 84/100\n",
            "324/324 [==============================] - 0s 361us/step - loss: 0.9275 - mean_absolute_error: 0.5677\n",
            "Epoch 85/100\n",
            "324/324 [==============================] - 0s 335us/step - loss: 0.7355 - mean_absolute_error: 0.4986\n",
            "Epoch 86/100\n",
            "324/324 [==============================] - 0s 363us/step - loss: 0.8400 - mean_absolute_error: 0.5680\n",
            "Epoch 87/100\n",
            "324/324 [==============================] - 0s 361us/step - loss: 0.8023 - mean_absolute_error: 0.5470\n",
            "Epoch 88/100\n",
            "324/324 [==============================] - 0s 333us/step - loss: 0.8156 - mean_absolute_error: 0.5548\n",
            "Epoch 89/100\n",
            "324/324 [==============================] - 0s 336us/step - loss: 0.9436 - mean_absolute_error: 0.5280\n",
            "Epoch 90/100\n",
            "324/324 [==============================] - 0s 323us/step - loss: 0.8559 - mean_absolute_error: 0.5520\n",
            "Epoch 91/100\n",
            "324/324 [==============================] - 0s 361us/step - loss: 0.8352 - mean_absolute_error: 0.5101\n",
            "Epoch 92/100\n",
            "324/324 [==============================] - 0s 332us/step - loss: 1.0696 - mean_absolute_error: 0.6476\n",
            "Epoch 93/100\n",
            "324/324 [==============================] - 0s 340us/step - loss: 1.1641 - mean_absolute_error: 0.6817\n",
            "Epoch 94/100\n",
            "324/324 [==============================] - 0s 336us/step - loss: 1.3094 - mean_absolute_error: 0.6895\n",
            "Epoch 95/100\n",
            "324/324 [==============================] - 0s 344us/step - loss: 1.2806 - mean_absolute_error: 0.7098\n",
            "Epoch 96/100\n",
            "324/324 [==============================] - 0s 342us/step - loss: 1.6225 - mean_absolute_error: 0.8166\n",
            "Epoch 97/100\n",
            "324/324 [==============================] - 0s 316us/step - loss: 2.2536 - mean_absolute_error: 0.8859\n",
            "Epoch 98/100\n",
            "324/324 [==============================] - 0s 332us/step - loss: 1.8060 - mean_absolute_error: 0.8227\n",
            "Epoch 99/100\n",
            "324/324 [==============================] - 0s 348us/step - loss: 1.6990 - mean_absolute_error: 0.7318\n",
            "Epoch 100/100\n",
            "324/324 [==============================] - 0s 318us/step - loss: 1.8339 - mean_absolute_error: 0.6929\n",
            "37/37 [==============================] - 1s 28ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 8ms/step - loss: 1747.1217 - mean_absolute_error: 29.8430\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 1655.5680 - mean_absolute_error: 28.3818\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 1243.1689 - mean_absolute_error: 22.4540\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 815.7792 - mean_absolute_error: 18.1376\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 643.9755 - mean_absolute_error: 16.6325\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 544.3305 - mean_absolute_error: 15.8441\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 421.9351 - mean_absolute_error: 14.0852\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 322.9639 - mean_absolute_error: 12.3097\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 323us/step - loss: 236.8590 - mean_absolute_error: 10.4823\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 171.2497 - mean_absolute_error: 9.0650\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 128.1548 - mean_absolute_error: 7.7960\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 99.9377 - mean_absolute_error: 6.7753\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 81.3108 - mean_absolute_error: 6.1494\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 64.4901 - mean_absolute_error: 5.3850\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 55.2563 - mean_absolute_error: 4.7687\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 47.7425 - mean_absolute_error: 4.5323\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 39.7485 - mean_absolute_error: 4.0862\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 34.1060 - mean_absolute_error: 3.6627\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 29.3577 - mean_absolute_error: 3.4527\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 25.8054 - mean_absolute_error: 3.1464\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 22.0794 - mean_absolute_error: 3.0213\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 354us/step - loss: 17.9160 - mean_absolute_error: 2.6526\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 15.0383 - mean_absolute_error: 2.4389\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 349us/step - loss: 12.7960 - mean_absolute_error: 2.2042\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 10.3680 - mean_absolute_error: 1.9966\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 9.2258 - mean_absolute_error: 1.9350\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 7.6579 - mean_absolute_error: 1.7082\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 5.9345 - mean_absolute_error: 1.4980\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 343us/step - loss: 4.9444 - mean_absolute_error: 1.4143\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 3.9862 - mean_absolute_error: 1.2540\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 3.4276 - mean_absolute_error: 1.1548\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 2.7483 - mean_absolute_error: 1.0291\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 326us/step - loss: 2.4095 - mean_absolute_error: 0.9673\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 376us/step - loss: 2.1172 - mean_absolute_error: 0.9170\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 1.8769 - mean_absolute_error: 0.8751\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 1.7834 - mean_absolute_error: 0.8472\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 1.6408 - mean_absolute_error: 0.7646\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 1.4946 - mean_absolute_error: 0.7421\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 1.3893 - mean_absolute_error: 0.7239\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 1.0823 - mean_absolute_error: 0.6691\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 0.8249 - mean_absolute_error: 0.5741\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 344us/step - loss: 0.8586 - mean_absolute_error: 0.5343\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 0.6314 - mean_absolute_error: 0.4945\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 0.6581 - mean_absolute_error: 0.4565\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 0.7479 - mean_absolute_error: 0.5727\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 0.9537 - mean_absolute_error: 0.5767\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 0.8416 - mean_absolute_error: 0.5203\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 1.0326 - mean_absolute_error: 0.5504\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 0.9740 - mean_absolute_error: 0.5929\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 349us/step - loss: 0.9837 - mean_absolute_error: 0.6317\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 0.7286 - mean_absolute_error: 0.5431\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 385us/step - loss: 0.7136 - mean_absolute_error: 0.4798\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 390us/step - loss: 0.7910 - mean_absolute_error: 0.5028\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 415us/step - loss: 0.9176 - mean_absolute_error: 0.4774\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 1.1952 - mean_absolute_error: 0.5703\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 1.5883 - mean_absolute_error: 0.6640\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 1.4030 - mean_absolute_error: 0.6620\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 1.7606 - mean_absolute_error: 0.7892\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 1.6874 - mean_absolute_error: 0.7426\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 1.5989 - mean_absolute_error: 0.8077\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 2.4914 - mean_absolute_error: 0.8540\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 1.5917 - mean_absolute_error: 0.8107\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 376us/step - loss: 1.3628 - mean_absolute_error: 0.6839\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 1.3777 - mean_absolute_error: 0.6724\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 0.7309 - mean_absolute_error: 0.5567\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 0.6486 - mean_absolute_error: 0.5175\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 0.4993 - mean_absolute_error: 0.4527\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 0.5379 - mean_absolute_error: 0.4489\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 0.5389 - mean_absolute_error: 0.4711\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 388us/step - loss: 0.5567 - mean_absolute_error: 0.4319\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 383us/step - loss: 0.7473 - mean_absolute_error: 0.4586\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 0.8028 - mean_absolute_error: 0.4517\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 0.7525 - mean_absolute_error: 0.5103\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 1.4254 - mean_absolute_error: 0.7316\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 2.0109 - mean_absolute_error: 0.8887\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 1.6401 - mean_absolute_error: 0.8203\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 1.6720 - mean_absolute_error: 0.8325\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 374us/step - loss: 1.8705 - mean_absolute_error: 0.8793\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 1.7912 - mean_absolute_error: 0.8211\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 1.7941 - mean_absolute_error: 0.8121\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 2.2816 - mean_absolute_error: 1.0403\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 2.3421 - mean_absolute_error: 1.0233\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 3.6448 - mean_absolute_error: 1.3282\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 350us/step - loss: 5.4472 - mean_absolute_error: 1.2386\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 2.4414 - mean_absolute_error: 1.0531\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 388us/step - loss: 1.8271 - mean_absolute_error: 0.9071\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 388us/step - loss: 1.3965 - mean_absolute_error: 0.7902\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 398us/step - loss: 1.1163 - mean_absolute_error: 0.6801\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 1.0859 - mean_absolute_error: 0.6039\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 0.9342 - mean_absolute_error: 0.6230\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 412us/step - loss: 0.8619 - mean_absolute_error: 0.5613\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 0.8221 - mean_absolute_error: 0.5463\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 0.9949 - mean_absolute_error: 0.6368\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 1.2698 - mean_absolute_error: 0.7277\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 1.1041 - mean_absolute_error: 0.6459\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 1.0878 - mean_absolute_error: 0.6155\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 1.1967 - mean_absolute_error: 0.7050\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 343us/step - loss: 1.2460 - mean_absolute_error: 0.7375\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 1.4491 - mean_absolute_error: 0.7536\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 1.5904 - mean_absolute_error: 0.8647\n",
            "36/36 [==============================] - 1s 30ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 8ms/step - loss: 1661.1473 - mean_absolute_error: 29.3157\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 1551.7867 - mean_absolute_error: 27.5926\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 374us/step - loss: 1114.5351 - mean_absolute_error: 20.7801\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 350us/step - loss: 732.7593 - mean_absolute_error: 16.9870\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 337us/step - loss: 598.3218 - mean_absolute_error: 15.9999\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 505.8041 - mean_absolute_error: 14.5240\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 326us/step - loss: 421.0374 - mean_absolute_error: 13.5136\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 343.1887 - mean_absolute_error: 12.8638\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 262.3417 - mean_absolute_error: 11.0964\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 198.8852 - mean_absolute_error: 9.7759\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 144.3121 - mean_absolute_error: 8.1861\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 106.5364 - mean_absolute_error: 7.1374\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 80.5166 - mean_absolute_error: 6.1204\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 64.5151 - mean_absolute_error: 5.5067\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 54.7037 - mean_absolute_error: 4.9448\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 45.8071 - mean_absolute_error: 4.5958\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 39.2960 - mean_absolute_error: 4.1654\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 33.8021 - mean_absolute_error: 3.8077\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 28.2736 - mean_absolute_error: 3.4508\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 24.4066 - mean_absolute_error: 3.1320\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 349us/step - loss: 21.1107 - mean_absolute_error: 2.9371\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 18.3228 - mean_absolute_error: 2.7133\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 354us/step - loss: 15.7233 - mean_absolute_error: 2.5002\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 13.7344 - mean_absolute_error: 2.3201\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 11.5887 - mean_absolute_error: 2.0940\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 9.9228 - mean_absolute_error: 1.8711\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 9.0074 - mean_absolute_error: 1.8134\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 7.3920 - mean_absolute_error: 1.6098\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 6.4638 - mean_absolute_error: 1.4920\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 5.7958 - mean_absolute_error: 1.4254\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 4.9501 - mean_absolute_error: 1.2813\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 4.2552 - mean_absolute_error: 1.1756\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 3.9549 - mean_absolute_error: 1.1226\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 3.4209 - mean_absolute_error: 1.0447\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 2.8488 - mean_absolute_error: 0.9292\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 2.4941 - mean_absolute_error: 0.8435\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 2.2763 - mean_absolute_error: 0.8373\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 1.9997 - mean_absolute_error: 0.7495\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 1.8065 - mean_absolute_error: 0.6938\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 1.6238 - mean_absolute_error: 0.6276\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 1.5943 - mean_absolute_error: 0.6175\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 1.3777 - mean_absolute_error: 0.5833\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 339us/step - loss: 1.3923 - mean_absolute_error: 0.6256\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 350us/step - loss: 1.2988 - mean_absolute_error: 0.5844\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 338us/step - loss: 1.2617 - mean_absolute_error: 0.5742\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 376us/step - loss: 1.2313 - mean_absolute_error: 0.5808\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 417us/step - loss: 1.1493 - mean_absolute_error: 0.5256\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 1.1814 - mean_absolute_error: 0.5663\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 1.2355 - mean_absolute_error: 0.5682\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 1.2843 - mean_absolute_error: 0.5921\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 392us/step - loss: 1.3066 - mean_absolute_error: 0.5662\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 1.4337 - mean_absolute_error: 0.5857\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 1.6429 - mean_absolute_error: 0.7037\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 1.7952 - mean_absolute_error: 0.7489\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 1.9924 - mean_absolute_error: 0.7523\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 401us/step - loss: 2.5153 - mean_absolute_error: 0.8938\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 389us/step - loss: 2.9920 - mean_absolute_error: 0.9910\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 2.1920 - mean_absolute_error: 0.8244\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 1.6046 - mean_absolute_error: 0.7109\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 1.4612 - mean_absolute_error: 0.6270\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 1.8956 - mean_absolute_error: 0.7106\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 1.4863 - mean_absolute_error: 0.6897\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 1.3552 - mean_absolute_error: 0.5908\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 1.2526 - mean_absolute_error: 0.5430\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 1.0217 - mean_absolute_error: 0.5045\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 0.9796 - mean_absolute_error: 0.4744\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 0.9885 - mean_absolute_error: 0.4960\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 1.4934 - mean_absolute_error: 0.6372\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 1.2787 - mean_absolute_error: 0.6137\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 1.4363 - mean_absolute_error: 0.5991\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 405us/step - loss: 1.2244 - mean_absolute_error: 0.5533\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 383us/step - loss: 1.1795 - mean_absolute_error: 0.5928\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 1.1513 - mean_absolute_error: 0.5874\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 0.9964 - mean_absolute_error: 0.5034\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 1.2174 - mean_absolute_error: 0.5647\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 1.5039 - mean_absolute_error: 0.6440\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 1.6763 - mean_absolute_error: 0.6891\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 375us/step - loss: 1.7469 - mean_absolute_error: 0.7356\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 1.8560 - mean_absolute_error: 0.7515\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 2.1542 - mean_absolute_error: 0.8691\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 2.1306 - mean_absolute_error: 0.8370\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 323us/step - loss: 1.7003 - mean_absolute_error: 0.7577\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 340us/step - loss: 1.4018 - mean_absolute_error: 0.6420\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 323us/step - loss: 1.4223 - mean_absolute_error: 0.6421\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 1.4062 - mean_absolute_error: 0.6226\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 2.0362 - mean_absolute_error: 0.8452\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 2.5468 - mean_absolute_error: 0.9685\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 2.6144 - mean_absolute_error: 0.9377\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 381us/step - loss: 2.5126 - mean_absolute_error: 0.9763\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 2.5497 - mean_absolute_error: 0.9927\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 2.1215 - mean_absolute_error: 0.9388\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 1.8474 - mean_absolute_error: 0.8716\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 1.8155 - mean_absolute_error: 0.8339\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 1.8932 - mean_absolute_error: 0.8294\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 2.2197 - mean_absolute_error: 0.9593\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 416us/step - loss: 2.7005 - mean_absolute_error: 1.0282\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 2.3828 - mean_absolute_error: 0.9779\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 1.7486 - mean_absolute_error: 0.7901\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 1.8272 - mean_absolute_error: 0.8212\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 2.2775 - mean_absolute_error: 0.9502\n",
            "36/36 [==============================] - 1s 30ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 9ms/step - loss: 1603.8786 - mean_absolute_error: 29.7530\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 381us/step - loss: 1495.7165 - mean_absolute_error: 28.0127\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 390us/step - loss: 1106.5963 - mean_absolute_error: 21.9070\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 376us/step - loss: 738.5512 - mean_absolute_error: 18.1389\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 384us/step - loss: 597.8821 - mean_absolute_error: 16.4901\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 508.2087 - mean_absolute_error: 15.5454\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 430.1822 - mean_absolute_error: 14.3217\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 401us/step - loss: 367.4640 - mean_absolute_error: 13.6601\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 350us/step - loss: 305.6108 - mean_absolute_error: 12.1255\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 249.5771 - mean_absolute_error: 11.4143\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 204.6753 - mean_absolute_error: 10.4458\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 399us/step - loss: 163.4655 - mean_absolute_error: 8.9772\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 128.4151 - mean_absolute_error: 8.1294\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 103.5317 - mean_absolute_error: 7.1957\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 384us/step - loss: 84.9382 - mean_absolute_error: 6.3688\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 378us/step - loss: 71.0324 - mean_absolute_error: 5.9108\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 59.5717 - mean_absolute_error: 5.2565\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 51.2373 - mean_absolute_error: 4.9000\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 44.1717 - mean_absolute_error: 4.5113\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 391us/step - loss: 37.9957 - mean_absolute_error: 4.1150\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 388us/step - loss: 32.6764 - mean_absolute_error: 3.8784\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 410us/step - loss: 28.3741 - mean_absolute_error: 3.5389\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 392us/step - loss: 25.2048 - mean_absolute_error: 3.3520\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 343us/step - loss: 21.3996 - mean_absolute_error: 3.1643\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 354us/step - loss: 18.5924 - mean_absolute_error: 2.8846\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 338us/step - loss: 15.7227 - mean_absolute_error: 2.6078\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 13.8042 - mean_absolute_error: 2.4382\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 384us/step - loss: 11.6135 - mean_absolute_error: 2.2490\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 9.6878 - mean_absolute_error: 2.0690\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 8.3364 - mean_absolute_error: 1.9162\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 7.2594 - mean_absolute_error: 1.7594\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 6.2087 - mean_absolute_error: 1.6356\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 5.3794 - mean_absolute_error: 1.5176\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 4.4032 - mean_absolute_error: 1.3455\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 3.7418 - mean_absolute_error: 1.2375\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 3.1725 - mean_absolute_error: 1.1433\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 395us/step - loss: 2.6909 - mean_absolute_error: 1.0431\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 2.3025 - mean_absolute_error: 0.9525\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 2.3455 - mean_absolute_error: 1.0287\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 1.9755 - mean_absolute_error: 0.9590\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 2.2994 - mean_absolute_error: 0.9140\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 387us/step - loss: 1.9368 - mean_absolute_error: 0.8862\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 383us/step - loss: 1.4589 - mean_absolute_error: 0.7241\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 408us/step - loss: 0.8767 - mean_absolute_error: 0.6006\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 376us/step - loss: 0.7328 - mean_absolute_error: 0.5256\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 395us/step - loss: 0.6268 - mean_absolute_error: 0.4833\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 0.5454 - mean_absolute_error: 0.4526\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 0.4829 - mean_absolute_error: 0.4127\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 0.4163 - mean_absolute_error: 0.3801\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 0.4222 - mean_absolute_error: 0.3836\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 0.4065 - mean_absolute_error: 0.3493\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 405us/step - loss: 0.4033 - mean_absolute_error: 0.3203\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 0.3640 - mean_absolute_error: 0.3005\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 401us/step - loss: 0.3076 - mean_absolute_error: 0.2779\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 0.2623 - mean_absolute_error: 0.2599\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 0.2079 - mean_absolute_error: 0.2458\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 0.1574 - mean_absolute_error: 0.2140\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 349us/step - loss: 0.1482 - mean_absolute_error: 0.1945\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 0.1487 - mean_absolute_error: 0.1965\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 375us/step - loss: 0.1535 - mean_absolute_error: 0.1936\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 0.1734 - mean_absolute_error: 0.1986\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 378us/step - loss: 0.1758 - mean_absolute_error: 0.2033\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 0.1906 - mean_absolute_error: 0.1939\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 383us/step - loss: 0.2079 - mean_absolute_error: 0.2044\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 344us/step - loss: 0.2235 - mean_absolute_error: 0.2176\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 354us/step - loss: 0.1492 - mean_absolute_error: 0.2033\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 0.1735 - mean_absolute_error: 0.1937\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 0.2017 - mean_absolute_error: 0.2084\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 406us/step - loss: 0.2550 - mean_absolute_error: 0.2532\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 383us/step - loss: 0.2835 - mean_absolute_error: 0.2474\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 0.2771 - mean_absolute_error: 0.2429\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 0.3210 - mean_absolute_error: 0.2843\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 0.3486 - mean_absolute_error: 0.2806\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 0.4352 - mean_absolute_error: 0.3348\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 0.4599 - mean_absolute_error: 0.3579\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 0.4483 - mean_absolute_error: 0.3462\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 0.5341 - mean_absolute_error: 0.3854\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 0.6997 - mean_absolute_error: 0.4056\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 0.4281 - mean_absolute_error: 0.4066\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 0.8402 - mean_absolute_error: 0.4476\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 1.2515 - mean_absolute_error: 0.4496\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 0.7156 - mean_absolute_error: 0.4567\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 0.6751 - mean_absolute_error: 0.4985\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 378us/step - loss: 0.7000 - mean_absolute_error: 0.5009\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 375us/step - loss: 0.6628 - mean_absolute_error: 0.5082\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 410us/step - loss: 0.7837 - mean_absolute_error: 0.5430\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 0.7103 - mean_absolute_error: 0.5215\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 374us/step - loss: 0.5776 - mean_absolute_error: 0.4827\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 0.7011 - mean_absolute_error: 0.4928\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 389us/step - loss: 0.9387 - mean_absolute_error: 0.5172\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 0.9935 - mean_absolute_error: 0.6557\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 0.9747 - mean_absolute_error: 0.6260\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 1.3281 - mean_absolute_error: 0.7288\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 401us/step - loss: 1.3049 - mean_absolute_error: 0.7085\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 0.9849 - mean_absolute_error: 0.6145\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 1.6325 - mean_absolute_error: 0.8134\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 1.7765 - mean_absolute_error: 0.8470\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 2.2075 - mean_absolute_error: 0.9199\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 1.2730 - mean_absolute_error: 0.7849\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 0.9416 - mean_absolute_error: 0.6521\n",
            "36/36 [==============================] - 1s 31ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 9ms/step - loss: 1715.7260 - mean_absolute_error: 29.5824\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 1535.5660 - mean_absolute_error: 26.9351\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 1048.5152 - mean_absolute_error: 20.2818\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 748.2496 - mean_absolute_error: 17.7150\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 610.8846 - mean_absolute_error: 16.5061\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 509.4058 - mean_absolute_error: 15.6616\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 411.3046 - mean_absolute_error: 13.9510\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 329.5868 - mean_absolute_error: 12.6067\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 257.7961 - mean_absolute_error: 11.6981\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 192.8218 - mean_absolute_error: 9.7430\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 152.0970 - mean_absolute_error: 9.0017\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 111.7554 - mean_absolute_error: 7.4332\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 87.9630 - mean_absolute_error: 6.5852\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 70.8217 - mean_absolute_error: 5.9257\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 59.5416 - mean_absolute_error: 5.3084\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 51.0000 - mean_absolute_error: 4.9691\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 42.6018 - mean_absolute_error: 4.4664\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 36.3366 - mean_absolute_error: 4.0491\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 31.9622 - mean_absolute_error: 3.7535\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 27.7967 - mean_absolute_error: 3.5202\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 23.7488 - mean_absolute_error: 3.2156\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 20.4893 - mean_absolute_error: 2.9640\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 17.9718 - mean_absolute_error: 2.7612\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 15.9194 - mean_absolute_error: 2.6135\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 13.3134 - mean_absolute_error: 2.3750\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 11.5125 - mean_absolute_error: 2.2090\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 9.7420 - mean_absolute_error: 1.9940\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 8.4206 - mean_absolute_error: 1.9015\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 7.4047 - mean_absolute_error: 1.7627\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 6.0445 - mean_absolute_error: 1.4795\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 5.2686 - mean_absolute_error: 1.3928\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 4.5571 - mean_absolute_error: 1.2771\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 389us/step - loss: 3.9340 - mean_absolute_error: 1.1585\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 3.2983 - mean_absolute_error: 1.0556\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 2.8106 - mean_absolute_error: 0.9438\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 2.5429 - mean_absolute_error: 0.9054\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 2.1355 - mean_absolute_error: 0.8318\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 344us/step - loss: 1.7751 - mean_absolute_error: 0.7543\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 1.5710 - mean_absolute_error: 0.7868\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 1.3392 - mean_absolute_error: 0.6841\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 1.2304 - mean_absolute_error: 0.6342\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 1.2926 - mean_absolute_error: 0.6024\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 0.9883 - mean_absolute_error: 0.5702\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 0.6954 - mean_absolute_error: 0.4850\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 0.5959 - mean_absolute_error: 0.4261\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 0.6273 - mean_absolute_error: 0.4301\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 0.6087 - mean_absolute_error: 0.4097\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 347us/step - loss: 0.7057 - mean_absolute_error: 0.4212\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 0.8673 - mean_absolute_error: 0.4817\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 1.1228 - mean_absolute_error: 0.5055\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 1.1191 - mean_absolute_error: 0.4820\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 0.7493 - mean_absolute_error: 0.4822\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 0.6402 - mean_absolute_error: 0.4557\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 0.6198 - mean_absolute_error: 0.4555\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 350us/step - loss: 0.6632 - mean_absolute_error: 0.4478\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 0.6601 - mean_absolute_error: 0.4222\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 0.6214 - mean_absolute_error: 0.4518\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 0.7097 - mean_absolute_error: 0.4495\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 0.7501 - mean_absolute_error: 0.4182\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 337us/step - loss: 0.6867 - mean_absolute_error: 0.4110\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 375us/step - loss: 0.4246 - mean_absolute_error: 0.3740\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 0.2771 - mean_absolute_error: 0.2925\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 0.2786 - mean_absolute_error: 0.2783\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 0.3086 - mean_absolute_error: 0.3015\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 350us/step - loss: 0.3484 - mean_absolute_error: 0.3067\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 0.5122 - mean_absolute_error: 0.3386\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 0.5456 - mean_absolute_error: 0.3452\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 393us/step - loss: 0.5991 - mean_absolute_error: 0.4029\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 0.6545 - mean_absolute_error: 0.4193\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 0.7064 - mean_absolute_error: 0.4224\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 0.8572 - mean_absolute_error: 0.4825\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 1.1553 - mean_absolute_error: 0.5334\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 1.3814 - mean_absolute_error: 0.5848\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 340us/step - loss: 1.2670 - mean_absolute_error: 0.6589\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 1.5227 - mean_absolute_error: 0.7165\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 1.3322 - mean_absolute_error: 0.6847\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 387us/step - loss: 1.0662 - mean_absolute_error: 0.6357\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 1.1037 - mean_absolute_error: 0.6278\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 388us/step - loss: 0.9010 - mean_absolute_error: 0.5873\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 384us/step - loss: 0.7967 - mean_absolute_error: 0.5208\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 0.7271 - mean_absolute_error: 0.5062\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 0.7325 - mean_absolute_error: 0.5077\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 0.6541 - mean_absolute_error: 0.4570\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 0.7447 - mean_absolute_error: 0.4774\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 1.0373 - mean_absolute_error: 0.5954\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 376us/step - loss: 0.8736 - mean_absolute_error: 0.5669\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 391us/step - loss: 0.9529 - mean_absolute_error: 0.6314\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 0.9784 - mean_absolute_error: 0.6496\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 0.7923 - mean_absolute_error: 0.5812\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 0.7116 - mean_absolute_error: 0.5060\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 1.1484 - mean_absolute_error: 0.6057\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 5.1677 - mean_absolute_error: 0.6946\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 1.0687 - mean_absolute_error: 0.7047\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 381us/step - loss: 1.0074 - mean_absolute_error: 0.6739\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 0.9990 - mean_absolute_error: 0.6081\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 354us/step - loss: 1.1284 - mean_absolute_error: 0.6043\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 1.5659 - mean_absolute_error: 0.7676\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 2.1623 - mean_absolute_error: 0.9497\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 2.2438 - mean_absolute_error: 0.9454\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 3.3353 - mean_absolute_error: 1.1613\n",
            "36/36 [==============================] - 1s 31ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 9ms/step - loss: 1715.3689 - mean_absolute_error: 29.6724\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 1480.4535 - mean_absolute_error: 26.5839\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 970.5079 - mean_absolute_error: 19.5903\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 738.3373 - mean_absolute_error: 18.0046\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 601.0792 - mean_absolute_error: 16.2161\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 497.5356 - mean_absolute_error: 15.2708\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 414.2019 - mean_absolute_error: 14.5210\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 327.9929 - mean_absolute_error: 12.4326\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 247.0396 - mean_absolute_error: 10.8432\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 392us/step - loss: 181.1888 - mean_absolute_error: 9.2711\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 378us/step - loss: 129.3588 - mean_absolute_error: 7.9297\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 375us/step - loss: 95.0411 - mean_absolute_error: 6.5943\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 76.2379 - mean_absolute_error: 5.7563\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 63.6420 - mean_absolute_error: 5.2407\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 52.0171 - mean_absolute_error: 4.6286\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 46.0340 - mean_absolute_error: 4.3832\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 40.1823 - mean_absolute_error: 4.2107\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 33.5845 - mean_absolute_error: 3.6980\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 348us/step - loss: 28.1040 - mean_absolute_error: 3.4497\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 337us/step - loss: 24.4996 - mean_absolute_error: 3.1547\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 21.4493 - mean_absolute_error: 2.9794\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 17.8279 - mean_absolute_error: 2.7199\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 14.7110 - mean_absolute_error: 2.5406\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 12.0992 - mean_absolute_error: 2.1870\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 345us/step - loss: 10.5865 - mean_absolute_error: 2.0897\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 8.8374 - mean_absolute_error: 1.8749\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 7.5278 - mean_absolute_error: 1.7851\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 6.6775 - mean_absolute_error: 1.6977\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 354us/step - loss: 5.6502 - mean_absolute_error: 1.5216\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 5.2787 - mean_absolute_error: 1.4322\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 392us/step - loss: 3.9309 - mean_absolute_error: 1.2413\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 399us/step - loss: 3.3377 - mean_absolute_error: 1.1377\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 2.7945 - mean_absolute_error: 1.0082\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 2.2399 - mean_absolute_error: 0.9215\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 347us/step - loss: 1.9990 - mean_absolute_error: 0.8815\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 1.9241 - mean_absolute_error: 0.8350\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 1.9232 - mean_absolute_error: 0.8059\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 347us/step - loss: 1.2885 - mean_absolute_error: 0.6941\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 1.0894 - mean_absolute_error: 0.6592\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 1.1890 - mean_absolute_error: 0.6288\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 0.9140 - mean_absolute_error: 0.5618\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 0.9331 - mean_absolute_error: 0.5652\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 1.0495 - mean_absolute_error: 0.5571\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 0.7974 - mean_absolute_error: 0.5232\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 387us/step - loss: 0.8819 - mean_absolute_error: 0.5214\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 1.1592 - mean_absolute_error: 0.5896\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 1.0678 - mean_absolute_error: 0.5840\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 1.3103 - mean_absolute_error: 0.5992\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 2.0047 - mean_absolute_error: 0.7087\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 337us/step - loss: 1.9206 - mean_absolute_error: 0.7686\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 1.9212 - mean_absolute_error: 0.7466\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 1.7438 - mean_absolute_error: 0.7182\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 1.9613 - mean_absolute_error: 0.7864\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 376us/step - loss: 3.6307 - mean_absolute_error: 1.0702\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 367us/step - loss: 1.9907 - mean_absolute_error: 0.9245\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 1.5392 - mean_absolute_error: 0.8232\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 1.5286 - mean_absolute_error: 0.7530\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 1.1431 - mean_absolute_error: 0.6178\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 1.1442 - mean_absolute_error: 0.6035\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 1.1356 - mean_absolute_error: 0.5301\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 398us/step - loss: 0.6601 - mean_absolute_error: 0.4512\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 1.8795 - mean_absolute_error: 0.7200\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 1.3867 - mean_absolute_error: 0.7626\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 1.2610 - mean_absolute_error: 0.7714\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 1.0529 - mean_absolute_error: 0.6416\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 1.2500 - mean_absolute_error: 0.6546\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 3.8570 - mean_absolute_error: 0.7414\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 1.6518 - mean_absolute_error: 0.7644\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 1.3604 - mean_absolute_error: 0.6685\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 1.3566 - mean_absolute_error: 0.7250\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 1.7043 - mean_absolute_error: 0.7492\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 1.4702 - mean_absolute_error: 0.7598\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 385us/step - loss: 1.4102 - mean_absolute_error: 0.7919\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 1.2624 - mean_absolute_error: 0.7038\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 409us/step - loss: 1.2862 - mean_absolute_error: 0.7111\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 1.1653 - mean_absolute_error: 0.6464\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 1.0122 - mean_absolute_error: 0.6355\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 390us/step - loss: 1.1933 - mean_absolute_error: 0.7083\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 398us/step - loss: 1.2122 - mean_absolute_error: 0.6854\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 394us/step - loss: 1.2322 - mean_absolute_error: 0.7198\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 393us/step - loss: 1.9400 - mean_absolute_error: 0.8339\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 397us/step - loss: 1.8246 - mean_absolute_error: 0.9429\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 400us/step - loss: 2.0240 - mean_absolute_error: 0.9699\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 1.9127 - mean_absolute_error: 0.8455\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 374us/step - loss: 2.8133 - mean_absolute_error: 1.0587\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 2.9931 - mean_absolute_error: 1.1156\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 2.5179 - mean_absolute_error: 1.0495\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 391us/step - loss: 2.2170 - mean_absolute_error: 0.9789\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 1.9401 - mean_absolute_error: 0.8494\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 387us/step - loss: 1.4819 - mean_absolute_error: 0.7635\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 378us/step - loss: 1.1948 - mean_absolute_error: 0.7010\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 388us/step - loss: 1.4872 - mean_absolute_error: 0.8233\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 1.7305 - mean_absolute_error: 0.8727\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 1.2262 - mean_absolute_error: 0.7624\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 0.9094 - mean_absolute_error: 0.6216\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 0.8455 - mean_absolute_error: 0.5942\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 0.8559 - mean_absolute_error: 0.6113\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 381us/step - loss: 0.9799 - mean_absolute_error: 0.6412\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 1.0836 - mean_absolute_error: 0.6614\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 1.0170 - mean_absolute_error: 0.6415\n",
            "36/36 [==============================] - 1s 32ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 9ms/step - loss: 1577.8811 - mean_absolute_error: 28.9624\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 1500.7613 - mean_absolute_error: 27.7483\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 378us/step - loss: 1120.5496 - mean_absolute_error: 22.0269\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 706.1821 - mean_absolute_error: 17.1431\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 575.5136 - mean_absolute_error: 16.2122\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 371us/step - loss: 471.4923 - mean_absolute_error: 14.9088\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 351us/step - loss: 378.1787 - mean_absolute_error: 12.8922\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 282.4602 - mean_absolute_error: 11.5110\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 315us/step - loss: 202.6164 - mean_absolute_error: 9.7807\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 343us/step - loss: 142.5146 - mean_absolute_error: 8.1193\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 97.2043 - mean_absolute_error: 6.7385\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 71.9725 - mean_absolute_error: 5.6428\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 57.4117 - mean_absolute_error: 5.1288\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 44.3921 - mean_absolute_error: 4.5026\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 36.1318 - mean_absolute_error: 3.9556\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 28.3427 - mean_absolute_error: 3.4539\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 344us/step - loss: 23.7332 - mean_absolute_error: 3.2686\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 319us/step - loss: 19.4301 - mean_absolute_error: 2.9557\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 15.5382 - mean_absolute_error: 2.5048\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 12.6025 - mean_absolute_error: 2.2799\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 326us/step - loss: 9.7583 - mean_absolute_error: 1.9750\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 384us/step - loss: 7.9413 - mean_absolute_error: 1.7639\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 6.4584 - mean_absolute_error: 1.6176\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 5.5474 - mean_absolute_error: 1.4533\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 4.9471 - mean_absolute_error: 1.4133\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 383us/step - loss: 3.8656 - mean_absolute_error: 1.2106\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 391us/step - loss: 3.1318 - mean_absolute_error: 1.0776\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 429us/step - loss: 2.7143 - mean_absolute_error: 1.0146\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 396us/step - loss: 2.2767 - mean_absolute_error: 0.8851\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 415us/step - loss: 2.0957 - mean_absolute_error: 0.7983\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 2.0737 - mean_absolute_error: 0.7782\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 2.2119 - mean_absolute_error: 0.7960\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 395us/step - loss: 2.0351 - mean_absolute_error: 0.7865\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 387us/step - loss: 1.4893 - mean_absolute_error: 0.6740\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 1.2835 - mean_absolute_error: 0.5850\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 412us/step - loss: 1.2482 - mean_absolute_error: 0.5273\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 388us/step - loss: 1.3370 - mean_absolute_error: 0.5181\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 1.3910 - mean_absolute_error: 0.5377\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 366us/step - loss: 1.2808 - mean_absolute_error: 0.5279\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 1.0709 - mean_absolute_error: 0.4818\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 385us/step - loss: 1.0585 - mean_absolute_error: 0.4687\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 362us/step - loss: 1.0984 - mean_absolute_error: 0.4645\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 0.9824 - mean_absolute_error: 0.3922\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 0.8485 - mean_absolute_error: 0.3430\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 377us/step - loss: 0.8876 - mean_absolute_error: 0.3504\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 0.9044 - mean_absolute_error: 0.3549\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 0.9426 - mean_absolute_error: 0.3684\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 1.0556 - mean_absolute_error: 0.3968\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 368us/step - loss: 1.2479 - mean_absolute_error: 0.4837\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 387us/step - loss: 1.5745 - mean_absolute_error: 0.5959\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 378us/step - loss: 1.7628 - mean_absolute_error: 0.5997\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 403us/step - loss: 1.9361 - mean_absolute_error: 0.6570\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 411us/step - loss: 1.7146 - mean_absolute_error: 0.6426\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 375us/step - loss: 1.6499 - mean_absolute_error: 0.6672\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 1.5805 - mean_absolute_error: 0.7095\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 1.5499 - mean_absolute_error: 0.6937\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 384us/step - loss: 1.8510 - mean_absolute_error: 0.7587\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 347us/step - loss: 1.9972 - mean_absolute_error: 0.8192\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 2.2566 - mean_absolute_error: 0.8386\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 2.1495 - mean_absolute_error: 0.7678\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 384us/step - loss: 2.0196 - mean_absolute_error: 0.7450\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 2.1259 - mean_absolute_error: 0.7108\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 2.1361 - mean_absolute_error: 0.6802\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 364us/step - loss: 2.6860 - mean_absolute_error: 0.7993\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 3.2303 - mean_absolute_error: 1.0784\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 2.3425 - mean_absolute_error: 0.9224\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 381us/step - loss: 1.7864 - mean_absolute_error: 0.7999\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 389us/step - loss: 1.6988 - mean_absolute_error: 0.6916\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 386us/step - loss: 1.2650 - mean_absolute_error: 0.5508\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 388us/step - loss: 1.3522 - mean_absolute_error: 0.5748\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 381us/step - loss: 1.2782 - mean_absolute_error: 0.5555\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 374us/step - loss: 1.3387 - mean_absolute_error: 0.6060\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 372us/step - loss: 1.2930 - mean_absolute_error: 0.5847\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 1.3365 - mean_absolute_error: 0.5944\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 1.6298 - mean_absolute_error: 0.6373\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 1.9067 - mean_absolute_error: 0.6949\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 354us/step - loss: 2.1712 - mean_absolute_error: 0.8233\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 380us/step - loss: 2.1910 - mean_absolute_error: 0.8719\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 370us/step - loss: 2.0140 - mean_absolute_error: 0.8303\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 1.5598 - mean_absolute_error: 0.7278\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 2.2527 - mean_absolute_error: 0.8157\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 1.5824 - mean_absolute_error: 0.6950\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 339us/step - loss: 1.5445 - mean_absolute_error: 0.7136\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 2.0181 - mean_absolute_error: 0.7040\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 1.4499 - mean_absolute_error: 0.6489\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 389us/step - loss: 1.4571 - mean_absolute_error: 0.6230\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 374us/step - loss: 1.5286 - mean_absolute_error: 0.6697\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 352us/step - loss: 1.7810 - mean_absolute_error: 0.7219\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 2.8598 - mean_absolute_error: 1.0255\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 3.1160 - mean_absolute_error: 1.0531\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 2.6461 - mean_absolute_error: 1.0181\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 2.7269 - mean_absolute_error: 0.9970\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 2.9768 - mean_absolute_error: 1.1383\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 404us/step - loss: 3.1736 - mean_absolute_error: 1.1199\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 390us/step - loss: 4.0272 - mean_absolute_error: 1.2720\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 337us/step - loss: 3.7145 - mean_absolute_error: 1.2641\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 2.9458 - mean_absolute_error: 1.1531\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 2.2692 - mean_absolute_error: 1.0010\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 2.1047 - mean_absolute_error: 0.8956\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 1.6018 - mean_absolute_error: 0.7529\n",
            "36/36 [==============================] - 1s 33ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 9ms/step - loss: 1579.2290 - mean_absolute_error: 28.4566\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 1481.1179 - mean_absolute_error: 26.8162\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 376us/step - loss: 1017.0831 - mean_absolute_error: 20.0581\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 734.6554 - mean_absolute_error: 17.4614\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 360us/step - loss: 596.5249 - mean_absolute_error: 15.4836\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 515.4239 - mean_absolute_error: 15.0519\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 373us/step - loss: 424.5388 - mean_absolute_error: 13.4546\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 394us/step - loss: 348.3506 - mean_absolute_error: 12.4496\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 382us/step - loss: 283.7057 - mean_absolute_error: 11.6007\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 413us/step - loss: 221.2334 - mean_absolute_error: 10.0342\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 401us/step - loss: 174.4872 - mean_absolute_error: 9.2653\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 397us/step - loss: 134.5782 - mean_absolute_error: 8.0458\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 413us/step - loss: 107.0300 - mean_absolute_error: 7.3113\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 415us/step - loss: 85.8902 - mean_absolute_error: 6.5014\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 458us/step - loss: 70.9345 - mean_absolute_error: 5.8858\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 432us/step - loss: 60.3951 - mean_absolute_error: 5.2873\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 440us/step - loss: 52.3407 - mean_absolute_error: 4.8586\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 462us/step - loss: 45.2373 - mean_absolute_error: 4.5045\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 444us/step - loss: 40.1113 - mean_absolute_error: 4.1727\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 438us/step - loss: 34.5989 - mean_absolute_error: 3.8653\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 429us/step - loss: 30.5849 - mean_absolute_error: 3.5554\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 444us/step - loss: 26.9164 - mean_absolute_error: 3.3449\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 463us/step - loss: 23.6829 - mean_absolute_error: 3.1108\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 440us/step - loss: 20.3006 - mean_absolute_error: 2.8482\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 430us/step - loss: 18.3473 - mean_absolute_error: 2.7038\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 421us/step - loss: 15.6452 - mean_absolute_error: 2.4354\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 469us/step - loss: 13.8573 - mean_absolute_error: 2.4305\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 433us/step - loss: 12.2706 - mean_absolute_error: 2.2319\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 455us/step - loss: 10.3668 - mean_absolute_error: 2.0226\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 439us/step - loss: 9.0135 - mean_absolute_error: 1.9147\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 433us/step - loss: 8.1765 - mean_absolute_error: 1.7725\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 437us/step - loss: 6.9488 - mean_absolute_error: 1.6625\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 416us/step - loss: 6.1402 - mean_absolute_error: 1.5044\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 421us/step - loss: 5.0964 - mean_absolute_error: 1.4080\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 447us/step - loss: 4.4715 - mean_absolute_error: 1.2975\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 456us/step - loss: 3.7893 - mean_absolute_error: 1.1721\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 469us/step - loss: 3.8042 - mean_absolute_error: 1.1684\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 495us/step - loss: 2.9429 - mean_absolute_error: 1.0564\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 469us/step - loss: 2.5086 - mean_absolute_error: 0.9651\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 487us/step - loss: 2.1377 - mean_absolute_error: 0.8800\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 567us/step - loss: 1.8760 - mean_absolute_error: 0.8295\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 599us/step - loss: 1.7399 - mean_absolute_error: 0.8044\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 623us/step - loss: 1.5322 - mean_absolute_error: 0.7403\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 658us/step - loss: 1.1608 - mean_absolute_error: 0.6402\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 641us/step - loss: 1.0409 - mean_absolute_error: 0.6027\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 641us/step - loss: 0.9594 - mean_absolute_error: 0.5640\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 649us/step - loss: 1.0299 - mean_absolute_error: 0.5924\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 577us/step - loss: 1.0467 - mean_absolute_error: 0.5822\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 597us/step - loss: 0.9432 - mean_absolute_error: 0.5517\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 618us/step - loss: 0.9064 - mean_absolute_error: 0.5052\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 628us/step - loss: 0.7271 - mean_absolute_error: 0.4784\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 605us/step - loss: 0.5807 - mean_absolute_error: 0.4586\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 617us/step - loss: 0.4590 - mean_absolute_error: 0.4008\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 629us/step - loss: 0.4192 - mean_absolute_error: 0.3639\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 626us/step - loss: 0.3936 - mean_absolute_error: 0.3430\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 658us/step - loss: 0.4452 - mean_absolute_error: 0.3829\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 597us/step - loss: 0.4837 - mean_absolute_error: 0.3648\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 577us/step - loss: 0.5219 - mean_absolute_error: 0.3507\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 572us/step - loss: 0.5381 - mean_absolute_error: 0.3614\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 565us/step - loss: 0.5428 - mean_absolute_error: 0.3545\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 554us/step - loss: 0.4429 - mean_absolute_error: 0.3291\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 603us/step - loss: 0.3590 - mean_absolute_error: 0.3014\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 587us/step - loss: 0.3343 - mean_absolute_error: 0.2837\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 636us/step - loss: 0.3302 - mean_absolute_error: 0.2699\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 625us/step - loss: 0.3731 - mean_absolute_error: 0.2956\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 610us/step - loss: 0.3600 - mean_absolute_error: 0.3184\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 613us/step - loss: 0.3802 - mean_absolute_error: 0.3040\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 580us/step - loss: 0.5183 - mean_absolute_error: 0.3430\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 587us/step - loss: 0.5260 - mean_absolute_error: 0.3434\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 573us/step - loss: 0.5136 - mean_absolute_error: 0.3289\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 564us/step - loss: 0.5081 - mean_absolute_error: 0.3355\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 443us/step - loss: 0.5041 - mean_absolute_error: 0.3267\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 387us/step - loss: 0.5570 - mean_absolute_error: 0.3548\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 0.6171 - mean_absolute_error: 0.3745\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 353us/step - loss: 0.8102 - mean_absolute_error: 0.4279\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 337us/step - loss: 0.9942 - mean_absolute_error: 0.4504\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 0.6338 - mean_absolute_error: 0.4461\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 0.8499 - mean_absolute_error: 0.5873\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 334us/step - loss: 0.9752 - mean_absolute_error: 0.6012\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 1.0192 - mean_absolute_error: 0.5846\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 1.5983 - mean_absolute_error: 0.8086\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 1.7899 - mean_absolute_error: 0.8742\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 1.5131 - mean_absolute_error: 0.7376\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 312us/step - loss: 1.2312 - mean_absolute_error: 0.6326\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 0.9788 - mean_absolute_error: 0.5920\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 314us/step - loss: 1.1629 - mean_absolute_error: 0.6390\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 318us/step - loss: 1.5973 - mean_absolute_error: 0.7209\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 1.7608 - mean_absolute_error: 0.7511\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 337us/step - loss: 1.4256 - mean_absolute_error: 0.7792\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 1.8781 - mean_absolute_error: 0.7787\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 321us/step - loss: 1.2422 - mean_absolute_error: 0.7703\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 1.2500 - mean_absolute_error: 0.7537\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 321us/step - loss: 0.8776 - mean_absolute_error: 0.6269\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 318us/step - loss: 0.6205 - mean_absolute_error: 0.5063\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 0.7233 - mean_absolute_error: 0.5082\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 0.7229 - mean_absolute_error: 0.5332\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 321us/step - loss: 0.5031 - mean_absolute_error: 0.4532\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 356us/step - loss: 0.4242 - mean_absolute_error: 0.4138\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 321us/step - loss: 0.4073 - mean_absolute_error: 0.4054\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 345us/step - loss: 0.4357 - mean_absolute_error: 0.4063\n",
            "36/36 [==============================] - 1s 33ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 9ms/step - loss: 1545.1922 - mean_absolute_error: 28.8910\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 1372.7252 - mean_absolute_error: 26.4173\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 326us/step - loss: 879.8508 - mean_absolute_error: 19.0459\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 323us/step - loss: 644.6684 - mean_absolute_error: 16.7295\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 337us/step - loss: 532.6121 - mean_absolute_error: 15.2060\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 443.9718 - mean_absolute_error: 13.8133\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 368.0036 - mean_absolute_error: 13.0808\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 300.2672 - mean_absolute_error: 11.6530\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 358us/step - loss: 236.8206 - mean_absolute_error: 10.3418\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 194.2177 - mean_absolute_error: 9.7106\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 143.9364 - mean_absolute_error: 8.3757\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 378us/step - loss: 115.6081 - mean_absolute_error: 7.5532\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 92.2920 - mean_absolute_error: 6.6965\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 75.1448 - mean_absolute_error: 5.9708\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 64.6153 - mean_absolute_error: 5.4509\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 55.1423 - mean_absolute_error: 5.0320\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 48.2479 - mean_absolute_error: 4.7415\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 323us/step - loss: 41.1483 - mean_absolute_error: 4.2414\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 338us/step - loss: 35.9463 - mean_absolute_error: 3.9786\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 32.0335 - mean_absolute_error: 3.6770\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 363us/step - loss: 28.0396 - mean_absolute_error: 3.4332\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 24.3405 - mean_absolute_error: 3.2379\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 20.7688 - mean_absolute_error: 3.0053\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 18.1023 - mean_absolute_error: 2.7474\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 15.9092 - mean_absolute_error: 2.5607\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 13.9857 - mean_absolute_error: 2.4539\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 369us/step - loss: 11.7955 - mean_absolute_error: 2.1817\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 361us/step - loss: 10.4159 - mean_absolute_error: 2.1193\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 9.0788 - mean_absolute_error: 1.9215\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 315us/step - loss: 7.7547 - mean_absolute_error: 1.7860\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 314us/step - loss: 6.8523 - mean_absolute_error: 1.6661\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 5.5555 - mean_absolute_error: 1.4987\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 319us/step - loss: 5.3867 - mean_absolute_error: 1.5021\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 4.2529 - mean_absolute_error: 1.3183\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 3.7869 - mean_absolute_error: 1.2391\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 3.2023 - mean_absolute_error: 1.1484\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 2.6628 - mean_absolute_error: 1.0274\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 2.3845 - mean_absolute_error: 0.9803\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 1.9794 - mean_absolute_error: 0.8947\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 322us/step - loss: 1.7669 - mean_absolute_error: 0.8399\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 303us/step - loss: 1.5826 - mean_absolute_error: 0.7600\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 318us/step - loss: 1.5285 - mean_absolute_error: 0.7448\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 1.3012 - mean_absolute_error: 0.7048\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 1.1494 - mean_absolute_error: 0.6995\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 0.9719 - mean_absolute_error: 0.6303\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 326us/step - loss: 0.8764 - mean_absolute_error: 0.5814\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 0.7255 - mean_absolute_error: 0.5254\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 0.6941 - mean_absolute_error: 0.5338\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 0.6064 - mean_absolute_error: 0.4614\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 309us/step - loss: 0.5790 - mean_absolute_error: 0.4060\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 326us/step - loss: 0.5402 - mean_absolute_error: 0.4082\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 0.5755 - mean_absolute_error: 0.4297\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 0.5181 - mean_absolute_error: 0.3886\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 0.5156 - mean_absolute_error: 0.3930\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 322us/step - loss: 0.6683 - mean_absolute_error: 0.4436\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 314us/step - loss: 0.6270 - mean_absolute_error: 0.4507\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 304us/step - loss: 0.6502 - mean_absolute_error: 0.4599\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 0.7568 - mean_absolute_error: 0.4563\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 306us/step - loss: 0.9767 - mean_absolute_error: 0.4778\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 339us/step - loss: 1.0996 - mean_absolute_error: 0.5900\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 309us/step - loss: 1.2783 - mean_absolute_error: 0.5784\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 1.5212 - mean_absolute_error: 0.6786\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 312us/step - loss: 0.6486 - mean_absolute_error: 0.5310\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 310us/step - loss: 0.4973 - mean_absolute_error: 0.4507\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 0.3948 - mean_absolute_error: 0.3952\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 0.3233 - mean_absolute_error: 0.3321\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 295us/step - loss: 0.1749 - mean_absolute_error: 0.2610\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 290us/step - loss: 0.2098 - mean_absolute_error: 0.2556\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 0.2592 - mean_absolute_error: 0.3430\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 316us/step - loss: 0.2642 - mean_absolute_error: 0.3254\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 301us/step - loss: 0.2388 - mean_absolute_error: 0.3072\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 307us/step - loss: 0.2028 - mean_absolute_error: 0.2645\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 326us/step - loss: 0.2418 - mean_absolute_error: 0.2526\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 0.3702 - mean_absolute_error: 0.3186\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 318us/step - loss: 0.6896 - mean_absolute_error: 0.4564\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 319us/step - loss: 1.1163 - mean_absolute_error: 0.5877\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 313us/step - loss: 1.2187 - mean_absolute_error: 0.6203\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 1.3084 - mean_absolute_error: 0.7095\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 1.2542 - mean_absolute_error: 0.7068\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 0.9873 - mean_absolute_error: 0.5918\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 303us/step - loss: 0.8193 - mean_absolute_error: 0.5753\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 318us/step - loss: 1.1898 - mean_absolute_error: 0.6140\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 1.3852 - mean_absolute_error: 0.6382\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 350us/step - loss: 1.5032 - mean_absolute_error: 0.7501\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 338us/step - loss: 1.5325 - mean_absolute_error: 0.7653\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 309us/step - loss: 1.6920 - mean_absolute_error: 0.8046\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 355us/step - loss: 1.8203 - mean_absolute_error: 0.8647\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 302us/step - loss: 1.8778 - mean_absolute_error: 0.8487\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 1.4782 - mean_absolute_error: 0.7480\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 322us/step - loss: 1.1130 - mean_absolute_error: 0.6822\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 310us/step - loss: 0.8335 - mean_absolute_error: 0.5950\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 309us/step - loss: 0.8533 - mean_absolute_error: 0.5701\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 1.1058 - mean_absolute_error: 0.6416\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 1.0555 - mean_absolute_error: 0.5974\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 319us/step - loss: 1.0539 - mean_absolute_error: 0.6324\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 318us/step - loss: 1.0841 - mean_absolute_error: 0.6235\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 315us/step - loss: 1.1844 - mean_absolute_error: 0.6988\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 319us/step - loss: 1.2678 - mean_absolute_error: 0.7104\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 1.4023 - mean_absolute_error: 0.7304\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 1.7814 - mean_absolute_error: 0.8871\n",
            "36/36 [==============================] - 1s 33ms/step\n",
            "Epoch 1/100\n",
            "325/325 [==============================] - 3s 9ms/step - loss: 1680.7270 - mean_absolute_error: 29.2291\n",
            "Epoch 2/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 1567.8678 - mean_absolute_error: 27.4782\n",
            "Epoch 3/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 1158.7478 - mean_absolute_error: 21.6310\n",
            "Epoch 4/100\n",
            "325/325 [==============================] - 0s 310us/step - loss: 764.8485 - mean_absolute_error: 17.3700\n",
            "Epoch 5/100\n",
            "325/325 [==============================] - 0s 323us/step - loss: 627.8714 - mean_absolute_error: 16.5058\n",
            "Epoch 6/100\n",
            "325/325 [==============================] - 0s 357us/step - loss: 532.8459 - mean_absolute_error: 15.1016\n",
            "Epoch 7/100\n",
            "325/325 [==============================] - 0s 347us/step - loss: 448.4141 - mean_absolute_error: 14.4503\n",
            "Epoch 8/100\n",
            "325/325 [==============================] - 0s 350us/step - loss: 370.6590 - mean_absolute_error: 13.0903\n",
            "Epoch 9/100\n",
            "325/325 [==============================] - 0s 318us/step - loss: 305.5959 - mean_absolute_error: 11.9194\n",
            "Epoch 10/100\n",
            "325/325 [==============================] - 0s 329us/step - loss: 249.1942 - mean_absolute_error: 11.1447\n",
            "Epoch 11/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 195.1751 - mean_absolute_error: 9.8550\n",
            "Epoch 12/100\n",
            "325/325 [==============================] - 0s 328us/step - loss: 152.6161 - mean_absolute_error: 8.4815\n",
            "Epoch 13/100\n",
            "325/325 [==============================] - 0s 314us/step - loss: 117.2327 - mean_absolute_error: 7.6421\n",
            "Epoch 14/100\n",
            "325/325 [==============================] - 0s 321us/step - loss: 94.4447 - mean_absolute_error: 6.8368\n",
            "Epoch 15/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 76.6134 - mean_absolute_error: 5.9606\n",
            "Epoch 16/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 65.8407 - mean_absolute_error: 5.4844\n",
            "Epoch 17/100\n",
            "325/325 [==============================] - 0s 339us/step - loss: 55.1573 - mean_absolute_error: 4.9482\n",
            "Epoch 18/100\n",
            "325/325 [==============================] - 0s 331us/step - loss: 47.7347 - mean_absolute_error: 4.5274\n",
            "Epoch 19/100\n",
            "325/325 [==============================] - 0s 315us/step - loss: 42.1191 - mean_absolute_error: 4.1602\n",
            "Epoch 20/100\n",
            "325/325 [==============================] - 0s 308us/step - loss: 36.4389 - mean_absolute_error: 3.9374\n",
            "Epoch 21/100\n",
            "325/325 [==============================] - 0s 307us/step - loss: 31.0272 - mean_absolute_error: 3.5559\n",
            "Epoch 22/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 28.3671 - mean_absolute_error: 3.3859\n",
            "Epoch 23/100\n",
            "325/325 [==============================] - 0s 305us/step - loss: 24.2973 - mean_absolute_error: 3.1100\n",
            "Epoch 24/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 19.9532 - mean_absolute_error: 2.7991\n",
            "Epoch 25/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 17.8446 - mean_absolute_error: 2.5912\n",
            "Epoch 26/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 14.7652 - mean_absolute_error: 2.3809\n",
            "Epoch 27/100\n",
            "325/325 [==============================] - 0s 318us/step - loss: 13.0800 - mean_absolute_error: 2.2073\n",
            "Epoch 28/100\n",
            "325/325 [==============================] - 0s 310us/step - loss: 11.2967 - mean_absolute_error: 2.0818\n",
            "Epoch 29/100\n",
            "325/325 [==============================] - 0s 336us/step - loss: 9.6518 - mean_absolute_error: 1.8548\n",
            "Epoch 30/100\n",
            "325/325 [==============================] - 0s 316us/step - loss: 8.4805 - mean_absolute_error: 1.7339\n",
            "Epoch 31/100\n",
            "325/325 [==============================] - 0s 326us/step - loss: 7.2318 - mean_absolute_error: 1.5840\n",
            "Epoch 32/100\n",
            "325/325 [==============================] - 0s 319us/step - loss: 6.2037 - mean_absolute_error: 1.4166\n",
            "Epoch 33/100\n",
            "325/325 [==============================] - 0s 315us/step - loss: 5.4335 - mean_absolute_error: 1.3587\n",
            "Epoch 34/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 4.5848 - mean_absolute_error: 1.2426\n",
            "Epoch 35/100\n",
            "325/325 [==============================] - 0s 333us/step - loss: 3.9859 - mean_absolute_error: 1.1683\n",
            "Epoch 36/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 3.5011 - mean_absolute_error: 1.1063\n",
            "Epoch 37/100\n",
            "325/325 [==============================] - 0s 322us/step - loss: 2.8031 - mean_absolute_error: 0.9801\n",
            "Epoch 38/100\n",
            "325/325 [==============================] - 0s 309us/step - loss: 2.3711 - mean_absolute_error: 0.9069\n",
            "Epoch 39/100\n",
            "325/325 [==============================] - 0s 335us/step - loss: 2.0119 - mean_absolute_error: 0.8199\n",
            "Epoch 40/100\n",
            "325/325 [==============================] - 0s 314us/step - loss: 1.8104 - mean_absolute_error: 0.8184\n",
            "Epoch 41/100\n",
            "325/325 [==============================] - 0s 309us/step - loss: 1.5957 - mean_absolute_error: 0.7541\n",
            "Epoch 42/100\n",
            "325/325 [==============================] - 0s 305us/step - loss: 1.3168 - mean_absolute_error: 0.6774\n",
            "Epoch 43/100\n",
            "325/325 [==============================] - 0s 322us/step - loss: 1.1521 - mean_absolute_error: 0.6528\n",
            "Epoch 44/100\n",
            "325/325 [==============================] - 0s 309us/step - loss: 0.9770 - mean_absolute_error: 0.6198\n",
            "Epoch 45/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 0.7738 - mean_absolute_error: 0.5210\n",
            "Epoch 46/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 0.6816 - mean_absolute_error: 0.4744\n",
            "Epoch 47/100\n",
            "325/325 [==============================] - 0s 323us/step - loss: 0.6100 - mean_absolute_error: 0.4529\n",
            "Epoch 48/100\n",
            "325/325 [==============================] - 0s 322us/step - loss: 0.5640 - mean_absolute_error: 0.4274\n",
            "Epoch 49/100\n",
            "325/325 [==============================] - 0s 365us/step - loss: 0.5198 - mean_absolute_error: 0.3977\n",
            "Epoch 50/100\n",
            "325/325 [==============================] - 0s 316us/step - loss: 0.6819 - mean_absolute_error: 0.4130\n",
            "Epoch 51/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 0.7949 - mean_absolute_error: 0.4279\n",
            "Epoch 52/100\n",
            "325/325 [==============================] - 0s 310us/step - loss: 0.6407 - mean_absolute_error: 0.4630\n",
            "Epoch 53/100\n",
            "325/325 [==============================] - 0s 340us/step - loss: 0.5832 - mean_absolute_error: 0.4088\n",
            "Epoch 54/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 0.6309 - mean_absolute_error: 0.4009\n",
            "Epoch 55/100\n",
            "325/325 [==============================] - 0s 341us/step - loss: 0.6699 - mean_absolute_error: 0.4128\n",
            "Epoch 56/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 0.8183 - mean_absolute_error: 0.4569\n",
            "Epoch 57/100\n",
            "325/325 [==============================] - 0s 308us/step - loss: 0.8326 - mean_absolute_error: 0.4720\n",
            "Epoch 58/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 0.8398 - mean_absolute_error: 0.4750\n",
            "Epoch 59/100\n",
            "325/325 [==============================] - 0s 316us/step - loss: 0.8951 - mean_absolute_error: 0.5331\n",
            "Epoch 60/100\n",
            "325/325 [==============================] - 0s 311us/step - loss: 1.3554 - mean_absolute_error: 0.6423\n",
            "Epoch 61/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 0.9393 - mean_absolute_error: 0.5276\n",
            "Epoch 62/100\n",
            "325/325 [==============================] - 0s 316us/step - loss: 0.9337 - mean_absolute_error: 0.5109\n",
            "Epoch 63/100\n",
            "325/325 [==============================] - 0s 321us/step - loss: 0.8746 - mean_absolute_error: 0.4613\n",
            "Epoch 64/100\n",
            "325/325 [==============================] - 0s 313us/step - loss: 0.7722 - mean_absolute_error: 0.4326\n",
            "Epoch 65/100\n",
            "325/325 [==============================] - 0s 317us/step - loss: 1.8099 - mean_absolute_error: 0.5026\n",
            "Epoch 66/100\n",
            "325/325 [==============================] - 0s 304us/step - loss: 0.5314 - mean_absolute_error: 0.4105\n",
            "Epoch 67/100\n",
            "325/325 [==============================] - 0s 305us/step - loss: 0.3789 - mean_absolute_error: 0.3533\n",
            "Epoch 68/100\n",
            "325/325 [==============================] - 0s 307us/step - loss: 0.3254 - mean_absolute_error: 0.3033\n",
            "Epoch 69/100\n",
            "325/325 [==============================] - 0s 308us/step - loss: 0.3020 - mean_absolute_error: 0.2571\n",
            "Epoch 70/100\n",
            "325/325 [==============================] - 0s 314us/step - loss: 0.3310 - mean_absolute_error: 0.2599\n",
            "Epoch 71/100\n",
            "325/325 [==============================] - 0s 299us/step - loss: 0.4033 - mean_absolute_error: 0.2981\n",
            "Epoch 72/100\n",
            "325/325 [==============================] - 0s 313us/step - loss: 0.4319 - mean_absolute_error: 0.3145\n",
            "Epoch 73/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 0.4444 - mean_absolute_error: 0.3372\n",
            "Epoch 74/100\n",
            "325/325 [==============================] - 0s 338us/step - loss: 0.4986 - mean_absolute_error: 0.3621\n",
            "Epoch 75/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 0.5322 - mean_absolute_error: 0.4253\n",
            "Epoch 76/100\n",
            "325/325 [==============================] - 0s 320us/step - loss: 0.6601 - mean_absolute_error: 0.4498\n",
            "Epoch 77/100\n",
            "325/325 [==============================] - 0s 315us/step - loss: 0.8155 - mean_absolute_error: 0.5083\n",
            "Epoch 78/100\n",
            "325/325 [==============================] - 0s 316us/step - loss: 0.7665 - mean_absolute_error: 0.5037\n",
            "Epoch 79/100\n",
            "325/325 [==============================] - 0s 315us/step - loss: 0.6500 - mean_absolute_error: 0.4229\n",
            "Epoch 80/100\n",
            "325/325 [==============================] - 0s 325us/step - loss: 0.8019 - mean_absolute_error: 0.4752\n",
            "Epoch 81/100\n",
            "325/325 [==============================] - 0s 315us/step - loss: 0.9706 - mean_absolute_error: 0.5372\n",
            "Epoch 82/100\n",
            "325/325 [==============================] - 0s 327us/step - loss: 0.9579 - mean_absolute_error: 0.5345\n",
            "Epoch 83/100\n",
            "325/325 [==============================] - 0s 330us/step - loss: 1.0025 - mean_absolute_error: 0.6002\n",
            "Epoch 84/100\n",
            "325/325 [==============================] - 0s 314us/step - loss: 1.1507 - mean_absolute_error: 0.6542\n",
            "Epoch 85/100\n",
            "325/325 [==============================] - 0s 313us/step - loss: 1.2901 - mean_absolute_error: 0.7192\n",
            "Epoch 86/100\n",
            "325/325 [==============================] - 0s 302us/step - loss: 1.0093 - mean_absolute_error: 0.5896\n",
            "Epoch 87/100\n",
            "325/325 [==============================] - 0s 340us/step - loss: 0.7770 - mean_absolute_error: 0.5453\n",
            "Epoch 88/100\n",
            "325/325 [==============================] - 0s 316us/step - loss: 0.9375 - mean_absolute_error: 0.5805\n",
            "Epoch 89/100\n",
            "325/325 [==============================] - 0s 307us/step - loss: 0.9506 - mean_absolute_error: 0.6065\n",
            "Epoch 90/100\n",
            "325/325 [==============================] - 0s 297us/step - loss: 0.7456 - mean_absolute_error: 0.5458\n",
            "Epoch 91/100\n",
            "325/325 [==============================] - 0s 312us/step - loss: 0.8928 - mean_absolute_error: 0.5613\n",
            "Epoch 92/100\n",
            "325/325 [==============================] - 0s 359us/step - loss: 0.8450 - mean_absolute_error: 0.5051\n",
            "Epoch 93/100\n",
            "325/325 [==============================] - 0s 316us/step - loss: 0.6997 - mean_absolute_error: 0.4841\n",
            "Epoch 94/100\n",
            "325/325 [==============================] - 0s 314us/step - loss: 0.6728 - mean_absolute_error: 0.4632\n",
            "Epoch 95/100\n",
            "325/325 [==============================] - 0s 308us/step - loss: 0.9434 - mean_absolute_error: 0.5846\n",
            "Epoch 96/100\n",
            "325/325 [==============================] - 0s 308us/step - loss: 0.8942 - mean_absolute_error: 0.5867\n",
            "Epoch 97/100\n",
            "325/325 [==============================] - 0s 319us/step - loss: 0.7502 - mean_absolute_error: 0.5374\n",
            "Epoch 98/100\n",
            "325/325 [==============================] - 0s 332us/step - loss: 0.7631 - mean_absolute_error: 0.5132\n",
            "Epoch 99/100\n",
            "325/325 [==============================] - 0s 324us/step - loss: 0.8473 - mean_absolute_error: 0.5005\n",
            "Epoch 100/100\n",
            "325/325 [==============================] - 0s 379us/step - loss: 0.9840 - mean_absolute_error: 0.5546\n",
            "36/36 [==============================] - 1s 35ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TaLPgvY6CLId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1662b933-d531-4121-dddb-aa61c3188a66"
      },
      "cell_type": "code",
      "source": [
        "print(accuracies)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-230.45125889 -222.92471059 -447.58772532 -574.98241001 -203.21721564\n",
            " -240.67563883 -553.83569845 -787.60904948 -598.80497233 -392.23950577]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QMryyxG-9bEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c786804-deb6-441e-dd4e-bea7254c6020"
      },
      "cell_type": "code",
      "source": [
        "print(mean)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-425.2328185313457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EZdjooMMR8cj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "3722016f-73a2-431d-ea0a-0be41ca98170"
      },
      "cell_type": "code",
      "source": [
        "regressor.fit(X_train,Y_train)\n",
        "predictions = regressor.predict(X_test)\n",
        "from sklearn.metrics import r2_score\n",
        "accuracy=r2_score(Y_test,predictions)\n",
        "print('test')\n",
        "print(accuracy)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-f9446af090ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 **self.filter_sk_params(self.build_fn.__call__))\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mloss_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-159-c5c478ae64d7>\u001b[0m in \u001b[0;36mbuild_regressor\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Sequential' object is not iterable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uhiaBSVDSFLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}